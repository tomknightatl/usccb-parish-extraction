{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Build Dioceses Database\n",
    "\n",
    "This notebook scrapes the USCCB website to build the initial dioceses database.\n",
    "\n",
    "**Prerequisites**: \n",
    "1. Run `00_Colab_Setup.ipynb` first\n",
    "2. Ensure your API keys are configured\n",
    "\n",
    "**What this does**:\n",
    "- Scrapes diocese information from the USCCB website\n",
    "- Extracts name, address, and website for each diocese\n",
    "- Saves the data to your Supabase database\n",
    "- Provides downloadable CSV backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_environment"
   },
   "outputs": [],
   "source": [
    "# Cell 1: Setup Environment and Imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Ensure we're in the correct directory and set up Python path\n",
    "repo_path = '/content/usccb-parish-extraction'\n",
    "\n",
    "if not os.path.exists(repo_path):\n",
    "    print(\"âŒ Repository not found!\")\n",
    "    print(\"Please run 00_Colab_Setup.ipynb first to clone the repository.\")\n",
    "    raise FileNotFoundError(\"Repository not found\")\n",
    "\n",
    "# Change to repository directory and add to Python path\n",
    "os.chdir(repo_path)\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.append(repo_path)\n",
    "\n",
    "print(f\"ğŸ“‚ Working directory: {os.getcwd()}\")\n",
    "print(\"ğŸ Python path configured\")\n",
    "\n",
    "# Now import the required modules\n",
    "try:\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import pandas as pd\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "\n",
    "    from config.settings import get_config\n",
    "    from src.utils.webdriver import setup_driver, load_page, clean_text\n",
    "    \n",
    "    print(\"âœ… All modules imported successfully\")\n",
    "    \nexcept ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")\n",
    "    print(\"\\nğŸ”§ Troubleshooting:\")\n",
    "    print(\"1. Make sure you've run 00_Colab_Setup.ipynb completely\")\n",
    "    print(\"2. If you restarted the runtime, re-run the setup notebook\")\n",
    "    print(\"3. Check that all required packages are installed\")\n",
    "    raise\n",
    "\n",
    "# Get configuration\n",
    "try:\n",
    "    config = get_config()\n",
    "    print(\"âœ… Configuration loaded successfully\")\n",
    "    print(f\"ğŸ“Š Database: {'Connected' if config.supabase else 'Not connected'}\")\n",
    "    print(f\"ğŸ¤– AI: {'Enabled' if config.genai_enabled else 'Mock mode'}\")\nexcept RuntimeError as e:\n",
    "    print(f\"âŒ Configuration error: {e}\")\n",
    "    print(\"\\nğŸ”§ Please run 00_Colab_Setup.ipynb first to configure your environment.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scrape_usccb"
   },
   "outputs": [],
   "source": [
    "# Cell 2: Scrape USCCB Dioceses Page\n",
    "def scrape_dioceses_from_usccb():\n",
    "    \"\"\"Scrape dioceses information from USCCB website\"\"\"\n",
    "    url = \"https://www.usccb.org/about/bishops-and-dioceses/all-dioceses\"\n",
    "    print(f\"ğŸ” Scraping dioceses from: {url}\")\n",
    "    \n",
    "    driver = setup_driver()\n",
    "    try:\n",
    "        print(\"â³ Loading page (this may take a moment)...\")\n",
    "        soup = load_page(driver, url)\n",
    "        print(\"âœ… Page loaded successfully\")\n",
    "        \n",
    "        # Find diocese containers\n",
    "        diocese_containers = soup.find_all('div', class_='views-row')\n",
    "        print(f\"ğŸ“‹ Found {len(diocese_containers)} potential diocese containers\")\n",
    "        \n",
    "        dioceses = []\n",
    "        \n",
    "        for i, container in enumerate(diocese_containers):\n",
    "            diocese_data = extract_diocese_info(container)\n",
    "            if diocese_data:\n",
    "                dioceses.append(diocese_data)\n",
    "                if len(dioceses) % 10 == 0:\n",
    "                    print(f\"   ğŸ“Š Processed {len(dioceses)} dioceses...\")\n",
    "        \n",
    "        print(f\"\\nâœ… Successfully extracted {len(dioceses)} dioceses\")\n",
    "        return dioceses\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during scraping: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        print(\"ğŸ”§ Browser closed\")\n",
    "\n",
    "def extract_diocese_info(container):\n",
    "    \"\"\"Extract diocese information from a container element\"\"\"\n",
    "    try:\n",
    "        da_wrap = container.find('div', class_='da-wrap')\n",
    "        if not da_wrap:\n",
    "            return None\n",
    "        \n",
    "        # Extract name\n",
    "        name_div = da_wrap.find('div', class_='da-title')\n",
    "        if not name_div:\n",
    "            return None\n",
    "        name = clean_text(name_div.get_text())\n",
    "        \n",
    "        # Extract address\n",
    "        address_div = da_wrap.find('div', class_='da-address')\n",
    "        address_parts = []\n",
    "        if address_div:\n",
    "            for div in address_div.find_all('div', recursive=False):\n",
    "                text = clean_text(div.get_text())\n",
    "                if text and text.strip():\n",
    "                    address_parts.append(text)\n",
    "        \n",
    "        address = \", \".join(address_parts) if address_parts else None\n",
    "        \n",
    "        # Extract website\n",
    "        website_div = da_wrap.find('div', class_='site')\n",
    "        website = None\n",
    "        if website_div:\n",
    "            link = website_div.find('a')\n",
    "            if link and link.get('href'):\n",
    "                website = link.get('href')\n",
    "                # Clean up the URL\n",
    "                if website and not website.startswith('http'):\n",
    "                    website = f\"https://{website}\"\n",
    "        \n",
    "        # Only return if we have a valid name\n",
    "        if name and len(name.strip()) > 2:\n",
    "            return {\n",
    "                'Name': name,\n",
    "                'Address': address,\n",
    "                'Website': website,\n",
    "                'extracted_at': datetime.now().isoformat()\n",
    "            }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error extracting diocese info: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Run the scraping\n",
    "print(\"ğŸš€ Starting USCCB diocese extraction...\\n\")\n",
    "dioceses_data = scrape_dioceses_from_usccb()\n",
    "print(f\"\\nğŸ‰ Extraction complete! Found {len(dioceses_data)} dioceses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze_data"
   },
   "outputs": [],
   "source": [
    "# Cell 3: Analyze and Display Results\n",
    "if dioceses_data:\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(dioceses_data)\n",
    "    \n",
    "    print(f\"ğŸ“Š DIOCESE EXTRACTION ANALYSIS\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Total dioceses extracted: {len(df)}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Statistics\n",
    "    missing_websites = df['Website'].isna().sum()\n",
    "    missing_addresses = df['Address'].isna().sum()\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ Data Quality:\")\n",
    "    print(f\"   âœ… Complete records: {len(df)}\")\n",
    "    print(f\"   ğŸŒ With websites: {len(df) - missing_websites} ({(len(df) - missing_websites)/len(df)*100:.1f}%)\")\n",
    "    print(f\"   ğŸ“ With addresses: {len(df) - missing_addresses} ({(len(df) - missing_addresses)/len(df)*100:.1f}%)\")\n",
    "    print(f\"   âŒ Missing websites: {missing_websites}\")\n",
    "    print(f\"   âŒ Missing addresses: {missing_addresses}\")\n",
    "    \n",
    "    # Show sample data\n",
    "    print(f\"\\nğŸ“‹ Sample Data (first 5 dioceses):\")\n",
    "    print(\"=\" * 50)\n",
    "    for i, row in df.head().iterrows():\n",
    "        print(f\"{i+1}. {row['Name']}\")\n",
    "        if row['Address']:\n",
    "            print(f\"   ğŸ“ {row['Address']}\")\n",
    "        if row['Website']:\n",
    "            print(f\"   ğŸŒ {row['Website']}\")\n",
    "        print()\n",
    "    \n",
    "    if len(df) > 5:\n",
    "        print(f\"... and {len(df) - 5} more dioceses\")\n",
    "    \n",
    "    # Check for duplicates\n",
    "    duplicates = df.duplicated(subset=['Name']).sum()\n",
    "    if duplicates > 0:\n",
    "        print(f\"\\nâš ï¸ Found {duplicates} potential duplicate dioceses\")\n",
    "        print(\"   These will be handled during database insertion\")\n",
    "    else:\n",
    "        print(f\"\\nâœ… No duplicate dioceses found\")\n",
    "\nelse:\n",
    "    print(\"âŒ No dioceses data was extracted\")\n",
    "    print(\"\\nğŸ”§ Troubleshooting:\")\n",
    "    print(\"   â€¢ Check your internet connection\")\n",
    "    print(\"   â€¢ The USCCB website might be temporarily unavailable\")\n",
    "    print(\"   â€¢ Try running the scraping cell again\")\n",
    "    df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_to_database"
   },
   "outputs": [],
   "source": [
    "# Cell 4: Save to Database\n",
    "if not df.empty and config.supabase:\n",
    "    print(\"ğŸ’¾ Saving dioceses to Supabase database...\\n\")\n",
    "    \n",
    "    # Convert DataFrame to list of dictionaries\n",
    "    records = df.to_dict('records')\n",
    "    \n",
    "    try:\n",
    "        # Insert data in batches to avoid timeouts\n",
    "        batch_size = 20\n",
    "        total_inserted = 0\n",
    "        errors = 0\n",
    "        \n",
    "        for i in range(0, len(records), batch_size):\n",
    "            batch = records[i:i + batch_size]\n",
    "            batch_num = i//batch_size + 1\n",
    "            \n",
    "            print(f\"ğŸ“¤ Inserting batch {batch_num}: {len(batch)} dioceses...\")\n",
    "            \n",
    "            try:\n",
    "                response = config.supabase.table('Dioceses').insert(batch).execute()\n",
    "                \n",
    "                if hasattr(response, 'error') and response.error:\n",
    "                    print(f\"   âŒ Database error: {response.error}\")\n",
    "                    errors += len(batch)\n",
    "                else:\n",
    "                    total_inserted += len(batch)\n",
    "                    print(f\"   âœ… Successfully inserted {len(batch)} dioceses\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                error_msg = str(e).lower()\n",
    "                if 'duplicate' in error_msg or 'unique' in error_msg:\n",
    "                    print(f\"   âš ï¸ Some dioceses already exist (duplicates skipped)\")\n",
    "                    # Count as successful since data exists\n",
    "                    total_inserted += len(batch)\n",
    "                else:\n",
    "                    print(f\"   âŒ Error inserting batch: {e}\")\n",
    "                    errors += len(batch)\n",
    "            \n",
    "            # Small delay between batches\n",
    "            if i + batch_size < len(records):\n",
    "                time.sleep(0.5)\n",
    "        \n",
    "        # Final results\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"ğŸ“Š DATABASE INSERTION RESULTS\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"Total dioceses processed: {len(df)}\")\n",
    "        print(f\"Successfully saved: {total_inserted}\")\n",
    "        print(f\"Errors/Skipped: {errors}\")\n",
    "        print(f\"Success rate: {total_inserted/len(df)*100:.1f}%\")\n",
    "        \n",
    "        if total_inserted > 0:\n",
    "            print(f\"\\nğŸ‰ Dioceses database built successfully!\")\n",
    "            print(f\"âœ… You can now run parish extraction notebooks\")\n",
    "        else:\n",
    "            print(f\"\\nâŒ No dioceses were saved to the database\")\n",
    "            print(f\"ğŸ”§ Check your database connection and try again\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Database operation failed: {e}\")\n",
    "        print(f\"\\nğŸ”§ Troubleshooting:\")\n",
    "        print(f\"   â€¢ Check your Supabase connection\")\n",
    "        print(f\"   â€¢ Verify the 'Dioceses' table exists\")\n",
    "        print(f\"   â€¢ Check your API key permissions\")\n",
    "\nelif df.empty:\n",
    "    print(\"âŒ No data to save - extraction may have failed\")\n",
    "    \nelse:\n",
    "    print(\"âš ï¸ Database not configured - data not saved to cloud\")\n",
    "    print(\"\\nğŸ’¡ But don't worry! Your data is still available in this session.\")\n",
    "    print(\"   You can export it to CSV in the next cell.\")\n",
    "    print(\"\\nğŸ”§ To enable database saving:\")\n",
    "    print(\"   â€¢ Add your Supabase credentials to Colab Secrets\")\n",
    "    print(\"   â€¢ Re-run the setup notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_csv"
   },
   "outputs": [],
   "source": [
    "# Cell 5: Export to CSV (Always useful as backup)\n",
    "if not df.empty:\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'usccb_dioceses_extracted_{timestamp}.csv'\n",
    "    \n",
    "    try:\n",
    "        # Save to CSV\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"ğŸ“ Data exported to: {filename}\")\n",
    "        print(f\"ğŸ“Š Exported {len(df)} dioceses\")\n",
    "        \n",
    "        # Show file size\n",
    "        file_size = os.path.getsize(filename) / 1024  # KB\n",
    "        print(f\"ğŸ“¦ File size: {file_size:.1f} KB\")\n",
    "        \n",
    "        # Download file in Colab\n",
    "        try:\n",
    "            from google.colab import files\n",
    "            files.download(filename)\n",
    "            print(f\"â¬‡ï¸ File downloaded to your computer\")\n",
    "            print(f\"\\nğŸ’¡ Tip: Keep this CSV as a backup of your dioceses data\")\n",
    "        except ImportError:\n",
    "            # Not in Colab environment\n",
    "            print(f\"ğŸ“ File saved locally: {filename}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Export failed: {e}\")\n",
    "        \nelse:\n",
    "    print(\"âŒ No data to export\")\n",
    "    print(\"\\nğŸ”§ The scraping may have failed. Try:\")\n",
    "    print(\"   â€¢ Re-running Cell 2 (the scraping cell)\")\n",
    "    print(\"   â€¢ Checking your internet connection\")\n",
    "    print(\"   â€¢ Waiting a moment and trying again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "completion_summary"
   },
   "source": [
    "## ğŸ‰ Dioceses Database Build Complete!\n",
    "\n",
    "If you see \"Dioceses database built successfully\" above, you're ready for the next step!\n",
    "\n",
    "### âœ… What You've Accomplished:\n",
    "- âœ… Scraped diocese data from the official USCCB website\n",
    "- âœ… Extracted names, addresses, and websites for all dioceses\n",
    "- âœ… Saved the data to your Supabase database\n",
    "- âœ… Created a CSV backup of the data\n",
    "\n",
    "### ğŸš€ Next Steps:\n",
    "\n",
    "1. **ğŸ¯ Quick Parish Extraction Demo**\n",
    "   - Open and run [`99_Simple_Demo.ipynb`](99_Simple_Demo.ipynb)\n",
    "   - This will extract parishes from a few dioceses\n",
    "\n",
    "2. **ğŸ” Find Parish Directories** \n",
    "   - Run [`02_Find_Parish_Directories.ipynb`](02_Find_Parish_Directories.ipynb)\n",
    "   - This finds parish directory URLs for all dioceses\n",
    "\n",
    "3. **ğŸ“¥ Extract All Parish Data**\n",
    "   - Run [`03_Extract_Parish_Data.ipynb`](03_Extract_Parish_Data.ipynb)\n",
    "   - This extracts detailed parish information\n",
    "\n",
    "### ğŸ› ï¸ Troubleshooting:\n",
    "\n",
    "**If the scraping failed:**\n",
    "- The USCCB website might be temporarily unavailable\n",
    "- Try re-running Cell 2 after a few minutes\n",
    "- Check your internet connection\n",
    "\n",
    "**If database saving failed:**\n",
    "- Check your Supabase credentials in the setup notebook\n",
    "- Verify your Supabase project is active\n",
    "- The CSV export still gives you the data\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ’¡ **Remember**: The CSV file you downloaded is a complete backup of all dioceses data!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}