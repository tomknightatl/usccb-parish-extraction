{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Build Dioceses Database\n",
    "\n",
    "This notebook scrapes the USCCB website to build the initial dioceses database.\n",
    "\n",
    "**What this does**:\n",
    "- Sets up the complete environment (no separate setup notebook needed)\n",
    "- Scrapes diocese information from the USCCB website\n",
    "- Extracts name, address, and website for each diocese\n",
    "- Saves the data to your Supabase database\n",
    "- Provides downloadable CSV backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "complete_setup"
   },
   "outputs": [],
   "source": [
    "# Cell 1: Complete Environment Setup\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üöÄ Setting up USCCB Parish Extraction Environment...\\n\")\n",
    "\n",
    "# Step 1: Clone repository if needed\n",
    "repo_path = '/content/usccb-parish-extraction'\n",
    "if not os.path.exists(repo_path):\n",
    "    print(\"üìÅ Cloning repository...\")\n",
    "    !git clone https://github.com/tomknightatl/usccb-parish-extraction.git\n",
    "    print(\"‚úÖ Repository cloned\")\n",
    "else:\n",
    "    print(\"‚úÖ Repository already exists\")\n",
    "    os.chdir(repo_path)\n",
    "    !git pull --quiet\n",
    "    print(\"‚úÖ Repository updated\")\n",
    "\n",
    "# Step 2: Set working directory and Python path\n",
    "os.chdir(repo_path)\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.insert(0, repo_path)\n",
    "print(f\"üìÇ Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Step 3: Install required packages\n",
    "print(\"\\nüì¶ Installing packages...\")\n",
    "!pip install --quiet selenium==4.15.0 webdriver-manager==4.0.1\n",
    "!pip install --quiet beautifulsoup4==4.12.2 lxml\n",
    "!pip install --quiet google-generativeai==0.3.0 tenacity==8.2.3\n",
    "!pip install --quiet \"supabase>=2.15.0\"\n",
    "print(\"‚úÖ Packages installed\")\n",
    "\n",
    "# Step 4: Test imports\n",
    "print(\"\\nüß™ Testing imports...\")\n",
    "try:\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    from bs4 import BeautifulSoup\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "    import selenium\n",
    "    import google.generativeai as genai\n",
    "    import supabase\n",
    "    print(\"‚úÖ External packages imported\")\n",
    "    \n",
    "    from config.settings import setup_environment, set_config, get_config\n",
    "    from src.utils.webdriver import setup_driver, load_page, clean_text\n",
    "    print(\"‚úÖ Project modules imported\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"\\nüîß Try restarting runtime and running this cell again\")\n",
    "    raise\n",
    "\n",
    "# Step 5: Configure APIs\n",
    "print(\"\\nüîë Configuring APIs...\")\n",
    "from google.colab import userdata\n",
    "\n",
    "try:\n",
    "    supabase_url = userdata.get('SUPABASE_URL')\n",
    "    supabase_key = userdata.get('SUPABASE_KEY')\n",
    "    genai_key = userdata.get('GENAI_API_KEY_USCCB')\n",
    "    \n",
    "    config = setup_environment(\n",
    "        supabase_url=supabase_url,\n",
    "        supabase_key=supabase_key,\n",
    "        genai_api_key=genai_key,\n",
    "        max_dioceses=10  # Can be changed\n",
    "    )\n",
    "    set_config(config)\n",
    "    \n",
    "    print(\"‚úÖ Configuration complete\")\n",
    "    print(f\"   üìä Database: {'Connected' if config.supabase else 'Not connected'}\")\n",
    "    print(f\"   ü§ñ AI: {'Enabled' if config.genai_enabled else 'Mock mode'}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Configuration error: {e}\")\n",
    "    print(\"\\nüîß Make sure to add your API keys to Colab Secrets:\")\n",
    "    print(\"   ‚Ä¢ SUPABASE_URL\")\n",
    "    print(\"   ‚Ä¢ SUPABASE_KEY\")\n",
    "    print(\"   ‚Ä¢ GENAI_API_KEY_USCCB\")\n",
    "    config = None\n",
    "\n",
    "print(\"\\nüéâ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scrape_usccb"
   },
   "outputs": [],
   "source": [
    "# Cell 2: Scrape USCCB Dioceses Page\n",
    "def scrape_dioceses_from_usccb():\n",
    "    \"\"\"Scrape dioceses information from USCCB website\"\"\"\n",
    "    url = \"https://www.usccb.org/about/bishops-and-dioceses/all-dioceses\"\n",
    "    print(f\"üîç Scraping dioceses from: {url}\")\n",
    "    \n",
    "    driver = setup_driver()\n",
    "    try:\n",
    "        print(\"‚è≥ Loading page (this may take a moment)...\")\n",
    "        soup = load_page(driver, url)\n",
    "        print(\"‚úÖ Page loaded successfully\")\n",
    "        \n",
    "        # Find diocese containers\n",
    "        diocese_containers = soup.find_all('div', class_='views-row')\n",
    "        print(f\"üìã Found {len(diocese_containers)} potential diocese containers\")\n",
    "        \n",
    "        dioceses = []\n",
    "        \n",
    "        for i, container in enumerate(diocese_containers):\n",
    "            diocese_data = extract_diocese_info(container)\n",
    "            if diocese_data:\n",
    "                dioceses.append(diocese_data)\n",
    "                if len(dioceses) % 10 == 0:\n",
    "                    print(f\"   üìä Processed {len(dioceses)} dioceses...\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Successfully extracted {len(dioceses)} dioceses\")\n",
    "        return dioceses\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during scraping: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        print(\"üîß Browser closed\")\n",
    "\n",
    "def extract_diocese_info(container):\n",
    "    \"\"\"Extract diocese information from a container element\"\"\"\n",
    "    try:\n",
    "        da_wrap = container.find('div', class_='da-wrap')\n",
    "        if not da_wrap:\n",
    "            return None\n",
    "        \n",
    "        # Extract name\n",
    "        name_div = da_wrap.find('div', class_='da-title')\n",
    "        if not name_div:\n",
    "            return None\n",
    "        name = clean_text(name_div.get_text())\n",
    "        \n",
    "        # Extract address\n",
    "        address_div = da_wrap.find('div', class_='da-address')\n",
    "        address_parts = []\n",
    "        if address_div:\n",
    "            for div in address_div.find_all('div', recursive=False):\n",
    "                text = clean_text(div.get_text())\n",
    "                if text and text.strip():\n",
    "                    address_parts.append(text)\n",
    "        \n",
    "        address = \", \".join(address_parts) if address_parts else None\n",
    "        \n",
    "        # Extract website\n",
    "        website_div = da_wrap.find('div', class_='site')\n",
    "        website = None\n",
    "        if website_div:\n",
    "            link = website_div.find('a')\n",
    "            if link and link.get('href'):\n",
    "                website = link.get('href')\n",
    "                # Clean up the URL\n",
    "                if website and not website.startswith('http'):\n",
    "                    website = f\"https://{website}\"\n",
    "        \n",
    "        # Only return if we have a valid name\n",
    "        if name and len(name.strip()) > 2:\n",
    "            return {\n",
    "                'Name': name,\n",
    "                'Address': address,\n",
    "                'Website': website,\n",
    "                'extracted_at': datetime.now().isoformat()\n",
    "            }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error extracting diocese info: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Run the scraping\n",
    "print(\"üöÄ Starting USCCB diocese extraction...\\n\")\n",
    "dioceses_data = scrape_dioceses_from_usccb()\n",
    "print(f\"\\nüéâ Extraction complete! Found {len(dioceses_data)} dioceses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze_data"
   },
   "outputs": [],
   "source": [
    "# Cell 3: Analyze and Display Results\n",
    "if dioceses_data:\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(dioceses_data)\n",
    "    \n",
    "    print(f\"üìä DIOCESE EXTRACTION ANALYSIS\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Total dioceses extracted: {len(df)}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Statistics\n",
    "    missing_websites = df['Website'].isna().sum()\n",
    "    missing_addresses = df['Address'].isna().sum()\n",
    "    \n",
    "    print(f\"\\nüìà Data Quality:\")\n",
    "    print(f\"   ‚úÖ Complete records: {len(df)}\")\n",
    "    print(f\"   üåê With websites: {len(df) - missing_websites} ({(len(df) - missing_websites)/len(df)*100:.1f}%)\")\n",
    "    print(f\"   üìç With addresses: {len(df) - missing_addresses} ({(len(df) - missing_addresses)/len(df)*100:.1f}%)\")\n",
    "    print(f\"   ‚ùå Missing websites: {missing_websites}\")\n",
    "    print(f\"   ‚ùå Missing addresses: {missing_addresses}\")\n",
    "    \n",
    "    # Show sample data\n",
    "    print(f\"\\nüìã Sample Data (first 5 dioceses):\")\n",
    "    print(\"=\" * 50)\n",
    "    for i, row in df.head().iterrows():\n",
    "        print(f\"{i+1}. {row['Name']}\")\n",
    "        if row['Address']:\n",
    "            print(f\"   üìç {row['Address']}\")\n",
    "        if row['Website']:\n",
    "            print(f\"   üåê {row['Website']}\")\n",
    "        print()\n",
    "    \n",
    "    if len(df) > 5:\n",
    "        print(f\"... and {len(df) - 5} more dioceses\")\n",
    "    \n",
    "    # Check for duplicates\n",
    "    duplicates = df.duplicated(subset=['Name']).sum()\n",
    "    if duplicates > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è Found {duplicates} potential duplicate dioceses\")\n",
    "        print(\"   These will be handled during database insertion\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ No duplicate dioceses found\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No dioceses data was extracted\")\n",
    "    print(\"\\nüîß Troubleshooting:\")\n",
    "    print(\"   ‚Ä¢ Check your internet connection\")\n",
    "    print(\"   ‚Ä¢ The USCCB website might be temporarily unavailable\")\n",
    "    print(\"   ‚Ä¢ Try running the scraping cell again\")\n",
    "    df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_to_database"
   },
   "outputs": [],
   "source": [
    "# Cell 4: Save to Database\n",
    "if not df.empty and config and config.supabase:\n",
    "    print(\"üíæ Saving dioceses to Supabase database...\\n\")\n",
    "    \n",
    "    # Convert DataFrame to list of dictionaries\n",
    "    records = df.to_dict('records')\n",
    "    \n",
    "    try:\n",
    "        # Insert data in batches to avoid timeouts\n",
    "        batch_size = 20\n",
    "        total_inserted = 0\n",
    "        errors = 0\n",
    "        \n",
    "        for i in range(0, len(records), batch_size):\n",
    "            batch = records[i:i + batch_size]\n",
    "            batch_num = i//batch_size + 1\n",
    "            \n",
    "            print(f\"üì§ Inserting batch {batch_num}: {len(batch)} dioceses...\")\n",
    "            \n",
    "            try:\n",
    "                response = config.supabase.table('Dioceses').insert(batch).execute()\n",
    "                \n",
    "                if hasattr(response, 'error') and response.error:\n",
    "                    print(f\"   ‚ùå Database error: {response.error}\")\n",
    "                    errors += len(batch)\n",
    "                else:\n",
    "                    total_inserted += len(batch)\n",
    "                    print(f\"   ‚úÖ Successfully inserted {len(batch)} dioceses\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                error_msg = str(e).lower()\n",
    "                if 'duplicate' in error_msg or 'unique' in error_msg:\n",
    "                    print(f\"   ‚ö†Ô∏è Some dioceses already exist (duplicates skipped)\")\n",
    "                    # Count as successful since data exists\n",
    "                    total_inserted += len(batch)\n",
    "                else:\n",
    "                    print(f\"   ‚ùå Error inserting batch: {e}\")\n",
    "                    errors += len(batch)\n",
    "            \n",
    "            # Small delay between batches\n",
    "            if i + batch_size < len(records):\n",
    "                time.sleep(0.5)\n",
    "        \n",
    "        # Final results\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"üìä DATABASE INSERTION RESULTS\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"Total dioceses processed: {len(df)}\")\n",
    "        print(f\"Successfully saved: {total_inserted}\")\n",
    "        print(f\"Errors/Skipped: {errors}\")\n",
    "        print(f\"Success rate: {total_inserted/len(df)*100:.1f}%\")\n",
    "        \n",
    "        if total_inserted > 0:\n",
    "            print(f\"\\nüéâ Dioceses database built successfully!\")\n",
    "            print(f\"‚úÖ You can now run parish extraction notebooks\")\n",
    "        else:\n",
    "            print(f\"\\n‚ùå No dioceses were saved to the database\")\n",
    "            print(f\"üîß Check your database connection and try again\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Database operation failed: {e}\")\n",
    "        print(f\"\\nüîß Troubleshooting:\")\n",
    "        print(f\"   ‚Ä¢ Check your Supabase connection\")\n",
    "        print(f\"   ‚Ä¢ Verify the 'Dioceses' table exists\")\n",
    "        print(f\"   ‚Ä¢ Check your API key permissions\")\n",
    "\n",
    "elif df.empty:\n",
    "    print(\"‚ùå No data to save - extraction may have failed\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Database not configured - data not saved to cloud\")\n",
    "    print(\"\\nüí° But don't worry! Your data is still available in this session.\")\n",
    "    print(\"   You can export it to CSV in the next cell.\")\n",
    "    print(\"\\nüîß To enable database saving:\")\n",
    "    print(\"   ‚Ä¢ Add your Supabase credentials to Colab Secrets\")\n",
    "    print(\"   ‚Ä¢ Re-run this notebook from the beginning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_csv"
   },
   "outputs": [],
   "source": [
    "# Cell 5: Export to CSV (Always useful as backup)\n",
    "if not df.empty:\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'usccb_dioceses_extracted_{timestamp}.csv'\n",
    "    \n",
    "    try:\n",
    "        # Save to CSV\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"üìÅ Data exported to: {filename}\")\n",
    "        print(f\"üìä Exported {len(df)} dioceses\")\n",
    "        \n",
    "        # Show file size\n",
    "        file_size = os.path.getsize(filename) / 1024  # KB\n",
    "        print(f\"üì¶ File size: {file_size:.1f} KB\")\n",
    "        \n",
    "        # Download file in Colab\n",
    "        try:\n",
    "            from google.colab import files\n",
    "            files.download(filename)\n",
    "            print(f\"‚¨áÔ∏è File downloaded to your computer\")\n",
    "            print(f\"\\nüí° Tip: Keep this CSV as a backup of your dioceses data\")\n",
    "        except ImportError:\n",
    "            # Not in Colab environment\n",
    "            print(f\"üìÅ File saved locally: {filename}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Export failed: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No data to export\")\n",
    "    print(\"\\nüîß The scraping may have failed. Try:\")\n",
    "    print(\"   ‚Ä¢ Re-running Cell 2 (the scraping cell)\")\n",
    "    print(\"   ‚Ä¢ Checking your internet connection\")\n",
    "    print(\"   ‚Ä¢ Waiting a moment and trying again\")\n",
    "\n",
    "print(\"\\nüéâ Diocese database build complete!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}