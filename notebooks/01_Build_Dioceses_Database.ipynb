{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Build Dioceses Database\n",
    "\n",
    "This notebook scrapes the USCCB website to build the initial dioceses database.\n",
    "\n",
    "**What this does**:\n",
    "- Sets up the complete environment (no separate setup notebook needed)\n",
    "- Scrapes diocese information from the USCCB website\n",
    "- Extracts name, address, and website for each diocese\n",
    "- Saves the data to your Supabase database\n",
    "- Provides downloadable CSV backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "complete_setup"
   },
   "outputs": [],
   "source": [
    "# Cell 1: Complete Environment Setup\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"🚀 Setting up USCCB Parish Extraction Environment...\\n\")\n",
    "\n",
    "# Step 1: Clone repository if needed\n",
    "repo_path = '/content/usccb-parish-extraction'\n",
    "if not os.path.exists(repo_path):\n",
    "    print(\"📁 Cloning repository...\")\n",
    "    !git clone https://github.com/tomknightatl/usccb-parish-extraction.git\n",
    "    print(\"✅ Repository cloned\")\n",
    "else:\n",
    "    print(\"✅ Repository already exists\")\n",
    "    os.chdir(repo_path)\n",
    "    !git pull --quiet\n",
    "    print(\"✅ Repository updated\")\n",
    "\n",
    "# Step 2: Set working directory and Python path\n",
    "os.chdir(repo_path)\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.insert(0, repo_path)\n",
    "print(f\"📂 Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Step 3: Install required packages\n",
    "print(\"\\n📦 Installing packages...\")\n",
    "!pip install --quiet selenium==4.15.0 webdriver-manager==4.0.1\n",
    "!pip install --quiet beautifulsoup4==4.12.2 lxml\n",
    "!pip install --quiet google-generativeai==0.3.0 tenacity==8.2.3\n",
    "!pip install --quiet \"supabase>=2.15.0\"\n",
    "print(\"✅ Packages installed\")\n",
    "\n",
    "# Step 4: Test imports\n",
    "print(\"\\n🧪 Testing imports...\")\n",
    "try:\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    from bs4 import BeautifulSoup\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "    import selenium\n",
    "    import google.generativeai as genai\n",
    "    import supabase\n",
    "    print(\"✅ External packages imported\")\n",
    "    \n",
    "    from config.settings import setup_environment, set_config, get_config\n",
    "    from src.utils.webdriver import setup_driver, load_page, clean_text\n",
    "    print(\"✅ Project modules imported\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"❌ Import error: {e}\")\n",
    "    print(\"\\n🔧 Try restarting runtime and running this cell again\")\n",
    "    raise\n",
    "\n",
    "# Step 5: Configure APIs\n",
    "print(\"\\n🔑 Configuring APIs...\")\n",
    "from google.colab import userdata\n",
    "\n",
    "try:\n",
    "    supabase_url = userdata.get('SUPABASE_URL')\n",
    "    supabase_key = userdata.get('SUPABASE_KEY')\n",
    "    genai_key = userdata.get('GENAI_API_KEY_USCCB')\n",
    "    \n",
    "    config = setup_environment(\n",
    "        supabase_url=supabase_url,\n",
    "        supabase_key=supabase_key,\n",
    "        genai_api_key=genai_key,\n",
    "        max_dioceses=10  # Can be changed\n",
    "    )\n",
    "    set_config(config)\n",
    "    \n",
    "    print(\"✅ Configuration complete\")\n",
    "    print(f\"   📊 Database: {'Connected' if config.supabase else 'Not connected'}\")\n",
    "    print(f\"   🤖 AI: {'Enabled' if config.genai_enabled else 'Mock mode'}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Configuration error: {e}\")\n",
    "    print(\"\\n🔧 Make sure to add your API keys to Colab Secrets:\")\n",
    "    print(\"   • SUPABASE_URL\")\n",
    "    print(\"   • SUPABASE_KEY\")\n",
    "    print(\"   • GENAI_API_KEY_USCCB\")\n",
    "    config = None\n",
    "\n",
    "print(\"\\n🎉 Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scrape_usccb"
   },
   "outputs": [],
   "source": [
    "# Cell 2: Scrape USCCB Dioceses Page\n",
    "def scrape_dioceses_from_usccb():\n",
    "    \"\"\"Scrape dioceses information from USCCB website\"\"\"\n",
    "    url = \"https://www.usccb.org/about/bishops-and-dioceses/all-dioceses\"\n",
    "    print(f\"🔍 Scraping dioceses from: {url}\")\n",
    "    \n",
    "    driver = setup_driver()\n",
    "    try:\n",
    "        print(\"⏳ Loading page (this may take a moment)...\")\n",
    "        soup = load_page(driver, url)\n",
    "        print(\"✅ Page loaded successfully\")\n",
    "        \n",
    "        # Find diocese containers\n",
    "        diocese_containers = soup.find_all('div', class_='views-row')\n",
    "        print(f\"📋 Found {len(diocese_containers)} potential diocese containers\")\n",
    "        \n",
    "        dioceses = []\n",
    "        \n",
    "        for i, container in enumerate(diocese_containers):\n",
    "            diocese_data = extract_diocese_info(container)\n",
    "            if diocese_data:\n",
    "                dioceses.append(diocese_data)\n",
    "                if len(dioceses) % 10 == 0:\n",
    "                    print(f\"   📊 Processed {len(dioceses)} dioceses...\")\n",
    "        \n",
    "        print(f\"\\n✅ Successfully extracted {len(dioceses)} dioceses\")\n",
    "        return dioceses\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during scraping: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        print(\"🔧 Browser closed\")\n",
    "\n",
    "def extract_diocese_info(container):\n",
    "    \"\"\"Extract diocese information from a container element\"\"\"\n",
    "    try:\n",
    "        da_wrap = container.find('div', class_='da-wrap')\n",
    "        if not da_wrap:\n",
    "            return None\n",
    "        \n",
    "        # Extract name\n",
    "        name_div = da_wrap.find('div', class_='da-title')\n",
    "        if not name_div:\n",
    "            return None\n",
    "        name = clean_text(name_div.get_text())\n",
    "        \n",
    "        # Extract address\n",
    "        address_div = da_wrap.find('div', class_='da-address')\n",
    "        address_parts = []\n",
    "        if address_div:\n",
    "            for div in address_div.find_all('div', recursive=False):\n",
    "                text = clean_text(div.get_text())\n",
    "                if text and text.strip():\n",
    "                    address_parts.append(text)\n",
    "        \n",
    "        address = \", \".join(address_parts) if address_parts else None\n",
    "        \n",
    "        # Extract website\n",
    "        website_div = da_wrap.find('div', class_='site')\n",
    "        website = None\n",
    "        if website_div:\n",
    "            link = website_div.find('a')\n",
    "            if link and link.get('href'):\n",
    "                website = link.get('href')\n",
    "                # Clean up the URL\n",
    "                if website and not website.startswith('http'):\n",
    "                    website = f\"https://{website}\"\n",
    "        \n",
    "        # Only return if we have a valid name\n",
    "        if name and len(name.strip()) > 2:\n",
    "            return {\n",
    "                'Name': name,\n",
    "                'Address': address,\n",
    "                'Website': website,\n",
    "                'extracted_at': datetime.now().isoformat()\n",
    "            }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error extracting diocese info: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Run the scraping\n",
    "print(\"🚀 Starting USCCB diocese extraction...\\n\")\n",
    "dioceses_data = scrape_dioceses_from_usccb()\n",
    "print(f\"\\n🎉 Extraction complete! Found {len(dioceses_data)} dioceses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze_data"
   },
   "outputs": [],
   "source": [
    "# Cell 3: Analyze and Display Results\n",
    "if dioceses_data:\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(dioceses_data)\n",
    "    \n",
    "    print(f\"📊 DIOCESE EXTRACTION ANALYSIS\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Total dioceses extracted: {len(df)}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Statistics\n",
    "    missing_websites = df['Website'].isna().sum()\n",
    "    missing_addresses = df['Address'].isna().sum()\n",
    "    \n",
    "    print(f\"\\n📈 Data Quality:\")\n",
    "    print(f\"   ✅ Complete records: {len(df)}\")\n",
    "    print(f\"   🌐 With websites: {len(df) - missing_websites} ({(len(df) - missing_websites)/len(df)*100:.1f}%)\")\n",
    "    print(f\"   📍 With addresses: {len(df) - missing_addresses} ({(len(df) - missing_addresses)/len(df)*100:.1f}%)\")\n",
    "    print(f\"   ❌ Missing websites: {missing_websites}\")\n",
    "    print(f\"   ❌ Missing addresses: {missing_addresses}\")\n",
    "    \n",
    "    # Show sample data\n",
    "    print(f\"\\n📋 Sample Data (first 5 dioceses):\")\n",
    "    print(\"=\" * 50)\n",
    "    for i, row in df.head().iterrows():\n",
    "        print(f\"{i+1}. {row['Name']}\")\n",
    "        if row['Address']:\n",
    "            print(f\"   📍 {row['Address']}\")\n",
    "        if row['Website']:\n",
    "            print(f\"   🌐 {row['Website']}\")\n",
    "        print()\n",
    "    \n",
    "    if len(df) > 5:\n",
    "        print(f\"... and {len(df) - 5} more dioceses\")\n",
    "    \n",
    "    # Check for duplicates\n",
    "    duplicates = df.duplicated(subset=['Name']).sum()\n",
    "    if duplicates > 0:\n",
    "        print(f\"\\n⚠️ Found {duplicates} potential duplicate dioceses\")\n",
    "        print(\"   These will be handled during database insertion\")\n",
    "    else:\n",
    "        print(f\"\\n✅ No duplicate dioceses found\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ No dioceses data was extracted\")\n",
    "    print(\"\\n🔧 Troubleshooting:\")\n",
    "    print(\"   • Check your internet connection\")\n",
    "    print(\"   • The USCCB website might be temporarily unavailable\")\n",
    "    print(\"   • Try running the scraping cell again\")\n",
    "    df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_to_database"
   },
   "outputs": [],
   "source": [
    "# Cell 4: Save to Database\n",
    "if not df.empty and config and config.supabase:\n",
    "    print(\"💾 Saving dioceses to Supabase database...\\n\")\n",
    "    \n",
    "    # Convert DataFrame to list of dictionaries\n",
    "    records = df.to_dict('records')\n",
    "    \n",
    "    try:\n",
    "        # Insert data in batches to avoid timeouts\n",
    "        batch_size = 20\n",
    "        total_inserted = 0\n",
    "        errors = 0\n",
    "        \n",
    "        for i in range(0, len(records), batch_size):\n",
    "            batch = records[i:i + batch_size]\n",
    "            batch_num = i//batch_size + 1\n",
    "            \n",
    "            print(f\"📤 Inserting batch {batch_num}: {len(batch)} dioceses...\")\n",
    "            \n",
    "            try:\n",
    "                response = config.supabase.table('Dioceses').insert(batch).execute()\n",
    "                \n",
    "                if hasattr(response, 'error') and response.error:\n",
    "                    print(f\"   ❌ Database error: {response.error}\")\n",
    "                    errors += len(batch)\n",
    "                else:\n",
    "                    total_inserted += len(batch)\n",
    "                    print(f\"   ✅ Successfully inserted {len(batch)} dioceses\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                error_msg = str(e).lower()\n",
    "                if 'duplicate' in error_msg or 'unique' in error_msg:\n",
    "                    print(f\"   ⚠️ Some dioceses already exist (duplicates skipped)\")\n",
    "                    # Count as successful since data exists\n",
    "                    total_inserted += len(batch)\n",
    "                else:\n",
    "                    print(f\"   ❌ Error inserting batch: {e}\")\n",
    "                    errors += len(batch)\n",
    "            \n",
    "            # Small delay between batches\n",
    "            if i + batch_size < len(records):\n",
    "                time.sleep(0.5)\n",
    "        \n",
    "        # Final results\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"📊 DATABASE INSERTION RESULTS\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"Total dioceses processed: {len(df)}\")\n",
    "        print(f\"Successfully saved: {total_inserted}\")\n",
    "        print(f\"Errors/Skipped: {errors}\")\n",
    "        print(f\"Success rate: {total_inserted/len(df)*100:.1f}%\")\n",
    "        \n",
    "        if total_inserted > 0:\n",
    "            print(f\"\\n🎉 Dioceses database built successfully!\")\n",
    "            print(f\"✅ You can now run parish extraction notebooks\")\n",
    "        else:\n",
    "            print(f\"\\n❌ No dioceses were saved to the database\")\n",
    "            print(f\"🔧 Check your database connection and try again\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Database operation failed: {e}\")\n",
    "        print(f\"\\n🔧 Troubleshooting:\")\n",
    "        print(f\"   • Check your Supabase connection\")\n",
    "        print(f\"   • Verify the 'Dioceses' table exists\")\n",
    "        print(f\"   • Check your API key permissions\")\n",
    "\n",
    "elif df.empty:\n",
    "    print(\"❌ No data to save - extraction may have failed\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ Database not configured - data not saved to cloud\")\n",
    "    print(\"\\n💡 But don't worry! Your data is still available in this session.\")\n",
    "    print(\"   You can export it to CSV in the next cell.\")\n",
    "    print(\"\\n🔧 To enable database saving:\")\n",
    "    print(\"   • Add your Supabase credentials to Colab Secrets\")\n",
    "    print(\"   • Re-run this notebook from the beginning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_csv"
   },
   "outputs": [],
   "source": [
    "# Cell 5: Export to CSV (Always useful as backup)\n",
    "if not df.empty:\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'usccb_dioceses_extracted_{timestamp}.csv'\n",
    "    \n",
    "    try:\n",
    "        # Save to CSV\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"📁 Data exported to: {filename}\")\n",
    "        print(f\"📊 Exported {len(df)} dioceses\")\n",
    "        \n",
    "        # Show file size\n",
    "        file_size = os.path.getsize(filename) / 1024  # KB\n",
    "        print(f\"📦 File size: {file_size:.1f} KB\")\n",
    "        \n",
    "        # Download file in Colab\n",
    "        try:\n",
    "            from google.colab import files\n",
    "            files.download(filename)\n",
    "            print(f\"⬇️ File downloaded to your computer\")\n",
    "            print(f\"\\n💡 Tip: Keep this CSV as a backup of your dioceses data\")\n",
    "        except ImportError:\n",
    "            # Not in Colab environment\n",
    "            print(f\"📁 File saved locally: {filename}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Export failed: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ No data to export\")\n",
    "    print(\"\\n🔧 The scraping may have failed. Try:\")\n",
    "    print(\"   • Re-running Cell 2 (the scraping cell)\")\n",
    "    print(\"   • Checking your internet connection\")\n",
    "    print(\"   • Waiting a moment and trying again\")\n",
    "\n",
    "print(\"\\n🎉 Diocese database build complete!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}