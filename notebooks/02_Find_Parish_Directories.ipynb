{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomknightatl/usccb-parish-extraction/blob/main/notebooks/02_Find_Parish_Directories.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# Find Parish Directories\n",
        "\n",
        "This notebook discovers parish directory URLs on diocesan websites using AI-powered analysis.\n",
        "\n",
        "**What this does**:\n",
        "- Sets up the complete environment (no separate setup notebook needed)\n",
        "- Analyzes diocese websites to find parish directory pages\n",
        "- Uses Google Gemini AI for intelligent link classification\n",
        "- Provides fallback search using mock responses\n",
        "- Saves discovered directory URLs to Supabase database\n",
        "\n",
        "**Prerequisites**: You should run `01_Build_Dioceses_Database.ipynb` first to populate dioceses data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "complete_setup",
        "outputId": "252e8a4c-6ff4-4ca9-ca31-00e1f1d0681e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Setting up USCCB Parish Extraction Environment...\n",
            "\n",
            "‚úÖ Repository already exists\n",
            "‚úÖ Repository updated\n",
            "üìÇ Working directory: /content/usccb-parish-extraction\n",
            "\n",
            "üì¶ Installing packages...\n",
            "üîß Setting up Chrome for Colab...\n",
            "‚úÖ Chrome installed: Google Chrome 137.0.7151.55 \n",
            "‚úÖ Packages installed\n",
            "\n",
            "üß™ Testing imports...\n",
            "‚úÖ External packages imported\n",
            "‚úÖ Project modules imported\n",
            "\n",
            "üîë Configuring APIs...\n",
            "‚úÖ Supabase connected\n",
            "‚úÖ Gemini AI configured\n",
            "\n",
            "üéâ Environment setup complete!\n",
            "   üìä Database: Connected\n",
            "   ü§ñ AI: Enabled\n",
            "\n",
            "üß™ Testing WebDriver...\n",
            "üîß Setting up Chrome WebDriver for Colab...\n",
            "  üîç Using Selenium auto-detection...\n",
            "  ‚úÖ Selenium auto-detection successful\n",
            "‚úÖ Chrome WebDriver setup successful\n",
            "‚úÖ WebDriver test successful\n"
          ]
        }
      ],
      "source": [
        "# Updated Cell 1: Complete Environment Setup with Fixed WebDriver\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"üöÄ Setting up USCCB Parish Extraction Environment...\\n\")\n",
        "\n",
        "# Step 1: Clone repository if needed\n",
        "repo_path = '/content/usccb-parish-extraction'\n",
        "if not os.path.exists(repo_path):\n",
        "    print(\"üìÅ Cloning repository...\")\n",
        "    !git clone https://github.com/tomknightatl/usccb-parish-extraction.git\n",
        "    print(\"‚úÖ Repository cloned\")\n",
        "else:\n",
        "    print(\"‚úÖ Repository already exists\")\n",
        "    os.chdir(repo_path)\n",
        "    !git pull --quiet\n",
        "    print(\"‚úÖ Repository updated\")\n",
        "\n",
        "# Step 2: Set working directory and Python path\n",
        "os.chdir(repo_path)\n",
        "if repo_path not in sys.path:\n",
        "    sys.path.insert(0, repo_path)\n",
        "print(f\"üìÇ Working directory: {os.getcwd()}\")\n",
        "\n",
        "# Step 3: Install required packages with specific Chrome setup for Colab\n",
        "print(\"\\nüì¶ Installing packages...\")\n",
        "!pip install --quiet selenium==4.15.0 webdriver-manager==4.0.1\n",
        "!pip install --quiet beautifulsoup4==4.12.2 lxml\n",
        "!pip install --quiet google-generativeai==0.3.0 tenacity==8.2.3\n",
        "!pip install --quiet \"supabase>=2.15.0\"\n",
        "\n",
        "# Setup Chrome for Colab with better error handling\n",
        "print(\"üîß Setting up Chrome for Colab...\")\n",
        "try:\n",
        "    !apt-get update >/dev/null 2>&1\n",
        "    !apt-get install -y wget gnupg >/dev/null 2>&1\n",
        "\n",
        "    # Add Google's signing key and repository\n",
        "    !wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | apt-key add - >/dev/null 2>&1\n",
        "    !echo \"deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main\" > /etc/apt/sources.list.d/google-chrome.list\n",
        "\n",
        "    # Update and install Chrome\n",
        "    !apt-get update >/dev/null 2>&1\n",
        "    !apt-get install -y google-chrome-stable >/dev/null 2>&1\n",
        "\n",
        "    # Check Chrome installation\n",
        "    chrome_version = !google-chrome --version 2>/dev/null\n",
        "    if chrome_version:\n",
        "        print(f\"‚úÖ Chrome installed: {chrome_version[0] if chrome_version else 'Unknown version'}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Chrome installation unclear, will try alternatives\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Chrome setup had issues: {e}\")\n",
        "    print(\"Will try alternative approaches in WebDriver setup\")\n",
        "\n",
        "print(\"‚úÖ Packages installed\")\n",
        "\n",
        "# Step 4: Import required modules\n",
        "print(\"\\nüß™ Testing imports...\")\n",
        "try:\n",
        "    import time\n",
        "    import re\n",
        "    from urllib.parse import urljoin, urlparse\n",
        "    from datetime import datetime\n",
        "    import requests\n",
        "    from bs4 import BeautifulSoup\n",
        "    import pandas as pd\n",
        "    import google.generativeai as genai\n",
        "    from selenium import webdriver\n",
        "    from selenium.webdriver.chrome.options import Options\n",
        "    from selenium.webdriver.chrome.service import Service\n",
        "    from selenium.common.exceptions import TimeoutException, WebDriverException\n",
        "    from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
        "    print(\"‚úÖ External packages imported\")\n",
        "\n",
        "    # Import project modules (these might need to be adapted)\n",
        "    try:\n",
        "        from config.settings import setup_environment, set_config, get_config\n",
        "        from src.utils.webdriver import setup_driver, load_page, clean_text\n",
        "        from src.utils.ai_analysis import analyze_with_ai\n",
        "        print(\"‚úÖ Project modules imported\")\n",
        "    except ImportError as e:\n",
        "        print(f\"‚ö†Ô∏è Project modules not available: {e}\")\n",
        "        print(\"Will use fallback implementations\")\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import error: {e}\")\n",
        "    print(\"\\nüîß Try restarting runtime and running this cell again\")\n",
        "    raise\n",
        "\n",
        "# Step 5: Colab-specific WebDriver setup function\n",
        "def setup_colab_driver():\n",
        "    \"\"\"Setup Chrome WebDriver specifically for Google Colab environment.\"\"\"\n",
        "    try:\n",
        "        print(\"üîß Setting up Chrome WebDriver for Colab...\")\n",
        "\n",
        "        chrome_options = Options()\n",
        "        chrome_options.add_argument('--headless')\n",
        "        chrome_options.add_argument('--no-sandbox')\n",
        "        chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "        chrome_options.add_argument('--disable-gpu')\n",
        "        chrome_options.add_argument('--window-size=1920,1080')\n",
        "        chrome_options.add_argument('--disable-extensions')\n",
        "        chrome_options.add_argument('--disable-plugins')\n",
        "        chrome_options.add_argument('--disable-images')\n",
        "        chrome_options.add_argument('--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36')\n",
        "        chrome_options.add_argument('--remote-debugging-port=9222')\n",
        "        chrome_options.add_argument('--disable-web-security')\n",
        "        chrome_options.add_argument('--allow-running-insecure-content')\n",
        "\n",
        "        # Start with the working approach (auto-detect)\n",
        "        print(\"  üîç Using Selenium auto-detection...\")\n",
        "        try:\n",
        "            driver = webdriver.Chrome(options=chrome_options)\n",
        "            print(\"  ‚úÖ Selenium auto-detection successful\")\n",
        "        except Exception as auto_error:\n",
        "            print(f\"  ‚ùå Auto-detection failed: {auto_error}\")\n",
        "\n",
        "            # Fallback to webdriver-manager\n",
        "            print(\"  üîÑ Trying webdriver-manager as fallback...\")\n",
        "            try:\n",
        "                from webdriver_manager.chrome import ChromeDriverManager\n",
        "                service = Service(ChromeDriverManager().install())\n",
        "                driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "                print(\"  ‚úÖ webdriver-manager approach successful\")\n",
        "            except Exception as wdm_error:\n",
        "                print(f\"  ‚ùå webdriver-manager also failed: {wdm_error}\")\n",
        "                raise Exception(\"All ChromeDriver approaches failed\")\n",
        "\n",
        "        # Test the driver\n",
        "        driver.set_page_load_timeout(30)\n",
        "        driver.get(\"data:text/html,<html><body><h1>Test</h1></body></html>\")\n",
        "\n",
        "        print(\"‚úÖ Chrome WebDriver setup successful\")\n",
        "        return driver\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå WebDriver setup failed: {e}\")\n",
        "        if 'driver' in locals() and driver:\n",
        "            try:\n",
        "                driver.quit()\n",
        "            except:\n",
        "                pass\n",
        "        return None\n",
        "\n",
        "# Step 6: Fallback implementations for missing project modules\n",
        "def fallback_load_page(driver, url, timeout=30):\n",
        "    \"\"\"Load a page and return BeautifulSoup object.\"\"\"\n",
        "    try:\n",
        "        driver.get(url)\n",
        "        time.sleep(2)  # Wait for page to load\n",
        "        html = driver.page_source\n",
        "        return BeautifulSoup(html, 'html.parser')\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading page {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "def fallback_analyze_with_ai(content, analysis_type=\"parish_directory\"):\n",
        "    \"\"\"Fallback AI analysis function.\"\"\"\n",
        "    # Simple keyword-based scoring as fallback\n",
        "    parish_keywords = [\n",
        "        'parish', 'church', 'directory', 'finder', 'location', 'mass',\n",
        "        'catholic', 'sacrament', 'worship', 'faith', 'community'\n",
        "    ]\n",
        "\n",
        "    content_lower = content.lower()\n",
        "    score = sum(10 for keyword in parish_keywords if keyword in content_lower)\n",
        "\n",
        "    # Boost score for certain patterns\n",
        "    if 'parish' in content_lower and ('directory' in content_lower or 'finder' in content_lower):\n",
        "        score += 30\n",
        "    if 'find' in content_lower and 'church' in content_lower:\n",
        "        score += 20\n",
        "\n",
        "    return {'score': min(score, 100)}\n",
        "\n",
        "# Step 7: Configure APIs\n",
        "print(\"\\nüîë Configuring APIs...\")\n",
        "from google.colab import userdata\n",
        "\n",
        "# Simple config class\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.supabase = None\n",
        "        self.genai_enabled = False\n",
        "        self.ai_confidence_threshold = 50\n",
        "        self.request_delay = 2\n",
        "\n",
        "config = Config()\n",
        "\n",
        "try:\n",
        "    supabase_url = userdata.get('SUPABASE_URL')\n",
        "    supabase_key = userdata.get('SUPABASE_KEY')\n",
        "    genai_key = userdata.get('GENAI_API_KEY_USCCB')\n",
        "\n",
        "    # Setup Supabase\n",
        "    if supabase_url and supabase_key:\n",
        "        from supabase import create_client\n",
        "        config.supabase = create_client(supabase_url, supabase_key)\n",
        "        print(\"‚úÖ Supabase connected\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Supabase credentials not found\")\n",
        "\n",
        "    # Setup Gemini AI\n",
        "    if genai_key:\n",
        "        genai.configure(api_key=genai_key)\n",
        "        config.genai_enabled = True\n",
        "        print(\"‚úÖ Gemini AI configured\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Gemini AI key not found - using fallback\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Configuration error: {e}\")\n",
        "    print(\"\\nüîß Make sure to add your API keys to Colab Secrets:\")\n",
        "    print(\"   ‚Ä¢ SUPABASE_URL\")\n",
        "    print(\"   ‚Ä¢ SUPABASE_KEY\")\n",
        "    print(\"   ‚Ä¢ GENAI_API_KEY_USCCB\")\n",
        "\n",
        "print(\"\\nüéâ Environment setup complete!\")\n",
        "print(f\"   üìä Database: {'Connected' if config.supabase else 'Not connected'}\")\n",
        "print(f\"   ü§ñ AI: {'Enabled' if config.genai_enabled else 'Fallback mode'}\")\n",
        "\n",
        "# Test the WebDriver setup\n",
        "print(\"\\nüß™ Testing WebDriver...\")\n",
        "test_driver = setup_colab_driver()\n",
        "if test_driver:\n",
        "    test_driver.quit()\n",
        "    print(\"‚úÖ WebDriver test successful\")\n",
        "else:\n",
        "    print(\"‚ùå WebDriver test failed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "parish_directory_functions",
        "outputId": "8c9ca2e0-4841-4bf6-dd1d-1e0f5dcdc04c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Parish directory discovery functions loaded\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Parish Directory Discovery Functions\n",
        "\n",
        "def normalize_url_join(base_url, relative_url):\n",
        "    \"\"\"Properly joins URLs while avoiding double slashes.\"\"\"\n",
        "    if base_url.endswith('/') and relative_url.startswith('/'):\n",
        "        base_url = base_url.rstrip('/')\n",
        "    return urljoin(base_url, relative_url)\n",
        "\n",
        "def get_surrounding_text(element, max_length=200):\n",
        "    \"\"\"Extracts context text from the parent element of a link.\"\"\"\n",
        "    if element and element.parent:\n",
        "        parent_text = element.parent.get_text(separator=' ', strip=True)\n",
        "        return parent_text[:max_length] + ('...' if len(parent_text) > max_length else '')\n",
        "    return ''\n",
        "\n",
        "def find_candidate_urls(soup, base_url):\n",
        "    \"\"\"Scans a webpage for potential parish directory links.\"\"\"\n",
        "    candidate_links = []\n",
        "    processed_hrefs = set()\n",
        "\n",
        "    # Keywords likely to appear in parish directory links\n",
        "    parish_link_keywords = [\n",
        "        'Churches', 'Directory of Parishes', 'Parishes', 'parishfinder', 'Parish Finder',\n",
        "        'Find a Parish', 'Locations', 'Our Parishes', 'Parish Listings', 'Find a Church',\n",
        "        'Church Directory', 'Faith Communities', 'Find Mass Times', 'Our Churches',\n",
        "        'Search Parishes', 'Parish Map', 'Mass Schedule', 'Sacraments', 'Worship'\n",
        "    ]\n",
        "\n",
        "    # URL path patterns for parish directories\n",
        "    url_patterns = [\n",
        "        r'parishes', r'directory', r'locations', r'churches',\n",
        "        r'parish-finder', r'findachurch', r'parishsearch', r'parishdirectory',\n",
        "        r'find-a-church', r'church-directory', r'parish-listings', r'parish-map',\n",
        "        r'mass-times', r'sacraments', r'search', r'worship', r'finder'\n",
        "    ]\n",
        "\n",
        "    all_links = soup.find_all('a', href=True)\n",
        "\n",
        "    for link_tag in all_links:\n",
        "        href = link_tag['href']\n",
        "        if not href or href.startswith('#') or href.lower().startswith('javascript:') or href.lower().startswith('mailto:'):\n",
        "            continue\n",
        "\n",
        "        abs_href = normalize_url_join(base_url, href)\n",
        "        if not abs_href.startswith('http') or abs_href in processed_hrefs:\n",
        "            continue\n",
        "\n",
        "        link_text = link_tag.get_text(strip=True)\n",
        "        surrounding_text = get_surrounding_text(link_tag)\n",
        "        parsed_href_path = urlparse(abs_href).path.lower()\n",
        "\n",
        "        # Check for matches based on keywords or URL patterns\n",
        "        text_match = any(keyword.lower() in link_text.lower() or keyword.lower() in surrounding_text.lower()\n",
        "                        for keyword in parish_link_keywords)\n",
        "        pattern_match = any(re.search(pattern, parsed_href_path, re.IGNORECASE)\n",
        "                           for pattern in url_patterns)\n",
        "\n",
        "        if text_match or pattern_match:\n",
        "            candidate_links.append({\n",
        "                'text': link_text,\n",
        "                'href': abs_href,\n",
        "                'surrounding_text': surrounding_text\n",
        "            })\n",
        "            processed_hrefs.add(abs_href)\n",
        "\n",
        "    return candidate_links\n",
        "\n",
        "def analyze_links_with_ai(candidate_links, diocese_name=None):\n",
        "    \"\"\"Analyzes candidate links using AI to find the best parish directory URL.\"\"\"\n",
        "    best_link = None\n",
        "    highest_score = -1\n",
        "\n",
        "    print(f\"    ü§ñ Analyzing {len(candidate_links)} candidate links with AI...\")\n",
        "\n",
        "    for link_info in candidate_links:\n",
        "        try:\n",
        "            # Create analysis prompt\n",
        "            link_context = f\"Link text: '{link_info['text']}', URL: '{link_info['href']}', Context: '{link_info['surrounding_text'][:100]}'\"\n",
        "\n",
        "            # Use the AI analysis utility\n",
        "            analysis = analyze_with_ai(link_context, \"parish_directory\")\n",
        "            score = analysis.get('score', 0)\n",
        "\n",
        "            print(f\"      üìä '{link_info['text'][:30]}...' -> Score: {score}\")\n",
        "\n",
        "            if score >= config.ai_confidence_threshold and score > highest_score:\n",
        "                highest_score = score\n",
        "                best_link = link_info['href']\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      ‚ùå Error analyzing link: {str(e)[:50]}...\")\n",
        "            continue\n",
        "\n",
        "    return best_link\n",
        "\n",
        "print(\"‚úÖ Parish directory discovery functions loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "database_functions",
        "outputId": "9386b18c-464a-4ad2-a5c7-79e83626fa0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Database and search functions loaded\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Database Functions\n",
        "\n",
        "def get_dioceses_to_process(limit=None):\n",
        "    \"\"\"Get dioceses that need parish directory URL discovery.\"\"\"\n",
        "    if not config or not config.supabase:\n",
        "        print(\"‚ùå No database connection\")\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        # Get all dioceses\n",
        "        response = config.supabase.table('Dioceses').select('Website, Name').execute()\n",
        "        all_dioceses = response.data or []\n",
        "\n",
        "        # Get dioceses that already have directory URLs\n",
        "        try:\n",
        "            processed_response = config.supabase.table('DiocesesParishDirectory').select(\n",
        "                'diocese_url'\n",
        "            ).not_.is_('parish_directory_url', 'null').not_.eq('parish_directory_url', '').execute()\n",
        "\n",
        "            processed_urls = {item['diocese_url'] for item in (processed_response.data or [])}\n",
        "        except:\n",
        "            # Table might not exist yet, process all dioceses\n",
        "            processed_urls = set()\n",
        "\n",
        "        # Filter to unprocessed dioceses\n",
        "        unprocessed = [\n",
        "            {'url': d['Website'], 'name': d['Name']}\n",
        "            for d in all_dioceses\n",
        "            if d.get('Website') and d['Website'] not in processed_urls\n",
        "        ]\n",
        "\n",
        "        if limit and len(unprocessed) > limit:\n",
        "            import random\n",
        "            unprocessed = random.sample(unprocessed, limit)\n",
        "\n",
        "        return unprocessed\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error fetching dioceses: {e}\")\n",
        "        return []\n",
        "\n",
        "def save_directory_result(diocese_url, directory_url, success, method=\"ai_analysis\"):\n",
        "    \"\"\"Save parish directory discovery result to database.\"\"\"\n",
        "    if not config or not config.supabase:\n",
        "        print(f\"  üìù Would save: {diocese_url} -> {directory_url or 'Not Found'}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        data = {\n",
        "            'diocese_url': diocese_url,\n",
        "            'parish_directory_url': directory_url,\n",
        "            'found': 'Success' if success else 'Not Found',\n",
        "            'found_method': method,\n",
        "            'updated_at': datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        config.supabase.table('DiocesesParishDirectory').upsert(data).execute()\n",
        "        print(f\"  üíæ Saved result to database\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå Error saving to database: {e}\")\n",
        "\n",
        "def search_for_directory_link(diocese_name, diocese_website_url):\n",
        "    \"\"\"Uses mock search results as fallback to find parish directory links.\"\"\"\n",
        "    print(f\"    üîç Using search engine fallback for {diocese_name}...\")\n",
        "\n",
        "    # Generate mock search results based on common patterns\n",
        "    print(f\"    üìù Using mock search results\")\n",
        "    mock_results = [\n",
        "        {\n",
        "            'link': normalize_url_join(diocese_website_url, '/parishes'),\n",
        "            'title': f\"Parishes - {diocese_name}\",\n",
        "            'snippet': f\"List of parishes in the Diocese of {diocese_name}. Find a parish near you.\"\n",
        "        },\n",
        "        {\n",
        "            'link': normalize_url_join(diocese_website_url, '/directory'),\n",
        "            'title': f\"Directory - {diocese_name}\",\n",
        "            'snippet': f\"Official directory of churches and schools for {diocese_name}.\"\n",
        "        },\n",
        "        {\n",
        "            'link': normalize_url_join(diocese_website_url, '/find-a-church'),\n",
        "            'title': f\"Find a Church - {diocese_name}\",\n",
        "            'snippet': f\"Search for a Catholic church in {diocese_name}. Mass times and locations.\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    return analyze_search_snippets_with_ai(mock_results, diocese_name)\n",
        "\n",
        "def analyze_search_snippets_with_ai(search_results, diocese_name):\n",
        "    \"\"\"Analyzes search result snippets to find the best parish directory URL.\"\"\"\n",
        "    best_link = None\n",
        "    highest_score = -1\n",
        "\n",
        "    print(f\"    ü§ñ Analyzing {len(search_results)} search snippets with AI...\")\n",
        "\n",
        "    for result in search_results:\n",
        "        try:\n",
        "            snippet_context = f\"Title: '{result.get('title', '')}', Snippet: '{result.get('snippet', '')}', URL: '{result.get('link', '')}'\"\n",
        "\n",
        "            analysis = analyze_with_ai(snippet_context, \"parish_directory\")\n",
        "            score = analysis.get('score', 0)\n",
        "\n",
        "            print(f\"      üìä '{result.get('title', '')[:30]}...' -> Score: {score}\")\n",
        "\n",
        "            if score >= config.ai_confidence_threshold and score > highest_score:\n",
        "                highest_score = score\n",
        "                best_link = result.get('link')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      ‚ùå Error analyzing snippet: {str(e)[:50]}...\")\n",
        "            continue\n",
        "\n",
        "    return best_link\n",
        "\n",
        "print(\"‚úÖ Database and search functions loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "main_processing",
        "outputId": "0fa11f75-1abf-4d7d-ef2a-b0147054dc47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting parish directory discovery...\n",
            "üìä Will process up to 5 dioceses\n",
            "üìã Found 5 dioceses to process\n",
            "üîß Setting up Chrome WebDriver for Colab...\n",
            "  üîç Using Selenium auto-detection...\n",
            "  ‚úÖ Selenium auto-detection successful\n",
            "‚úÖ Chrome WebDriver setup successful\n",
            "\\n============================================================\n",
            "Processing diocese 1/5\n",
            "\\nüèõÔ∏è Processing: Diocese of Des Moines\n",
            "  üìç URL: https://www.dmdiocese.org\n",
            "  üì• Loading website...\n",
            "  üîç Scanning for parish directory links...\n",
            "  üìã Found 12 candidate links\n",
            "    ü§ñ Analyzing 12 candidate links...\n",
            "      üìä 'Diocesan Directory...' -> Score: 10\n",
            "      üìä 'Hispanic Ministry...' -> Score: 20\n",
            "      üìä 'Parishes with Hispanic Service...' -> Score: 20\n",
            "      üìä 'Worship...' -> Score: 30\n",
            "      üìä 'Parishes & Mass Times...' -> Score: 30\n",
            "      üìä 'Why Mass...' -> Score: 20\n",
            "      üìä 'Eucharistic Adoration...' -> Score: 10\n",
            "      üìä 'Holy Days & Calendar...' -> Score: 10\n",
            "      üìä 'Lent...' -> Score: 10\n",
            "      üìä 'Sacraments...' -> Score: 20\n",
            "      üìä '...' -> Score: 10\n",
            "      üìä '...' -> Score: 10\n",
            "  ‚ùå No parish directory URL found\n",
            "  üíæ Saved result to database\n",
            "  ‚è±Ô∏è Waiting 2 seconds...\n",
            "\\n============================================================\n",
            "Processing diocese 2/5\n",
            "\\nüèõÔ∏è Processing: Armenian Catholic Eparchy of Our Lady of Nareg in the USA & Canada\n",
            "  üìç URL: https://www.ourladyofnareg.org\n",
            "  üì• Loading website...\n",
            "  üîç Scanning for parish directory links...\n",
            "  ‚ö†Ô∏è No candidate links found on main page\n",
            "    üîç Testing common directory paths...\n",
            "      üîç Testing: https://www.ourladyofnareg.org/parishes\n",
            "      ‚ùå Failed: /parishes - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/directory\n",
            "      ‚ùå Failed: /directory - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/parish-directory\n",
            "      ‚ùå Failed: /parish-directory - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/find-a-parish\n",
            "      ‚ùå Failed: /find-a-parish - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/churches\n",
            "      ‚ùå Failed: /churches - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/locations\n",
            "      ‚ùå Failed: /locations - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/parish-finder\n",
            "      ‚ùå Failed: /parish-finder - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/church-directory\n",
            "      ‚ùå Failed: /church-directory - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/find-a-church\n",
            "      ‚ùå Failed: /find-a-church - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/parish-listings\n",
            "      ‚ùå Failed: /parish-listings - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/parish-map\n",
            "      ‚ùå Failed: /parish-map - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/worship\n",
            "      ‚ùå Failed: /worship - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/sacraments\n",
            "      ‚ùå Failed: /sacraments - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/en/eparchy/map-of-eparchy.html\n",
            "      ‚ùå Failed: /en/eparchy/map-of-eparchy.html - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/eparchy/map-of-eparchy\n",
            "      ‚ùå Failed: /eparchy/map-of-eparchy - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/map-of-eparchy\n",
            "      ‚ùå Failed: /map-of-eparchy - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/eparchy/parishes\n",
            "      ‚ùå Failed: /eparchy/parishes - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/en/parishes\n",
            "      ‚ùå Failed: /en/parishes - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/our-parishes\n",
            "      ‚ùå Failed: /our-parishes - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/communities\n",
            "      ‚ùå Failed: /communities - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/catholic-churches\n",
            "      ‚ùå Failed: /catholic-churches - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/church-locator\n",
            "      ‚ùå Failed: /church-locator - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/mass-times\n",
            "      ‚ùå Failed: /mass-times - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/parish-search\n",
            "      ‚ùå Failed: /parish-search - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/ministries\n",
            "      ‚ùå Failed: /ministries - HTTPSConnectionPool(host='www....\n",
            "      üîç Testing: https://www.ourladyofnareg.org/about/parishes\n",
            "      ‚ùå Failed: /about/parishes - HTTPSConnectionPool(host='www....\n",
            "    ‚ùå No standard directory paths found\n",
            "    üîç Scanning main page more thoroughly...\n",
            "    ‚ùå Error scanning main page: HTTPSConnectionPool(host='www.ourladyofnareg.org',...\n",
            "  ‚ùå No parish directory URL found\n",
            "  üíæ Saved result to database\n",
            "  ‚è±Ô∏è Waiting 2 seconds...\n",
            "\\n============================================================\n",
            "Processing diocese 3/5\n",
            "\\nüèõÔ∏è Processing: Archdiocese of Kansas City in Kansas\n",
            "  üìç URL: https://www.archkck.org\n",
            "  üì• Loading website...\n",
            "  üîç Scanning for parish directory links...\n",
            "  üìã Found 6 candidate links\n",
            "    ü§ñ Analyzing 6 candidate links...\n",
            "      üìä 'Parishes & Schools...' -> Score: 20\n",
            "      üìä 'Catholic Parishes...' -> Score: 30\n",
            "      üìä 'Children‚Äôs Catechesis/Religiou...' -> Score: 20\n",
            "      üìä 'Find Your Parish...' -> Score: 20\n",
            "      üìä 'Liturgy & Sacramental Life...' -> Score: 30\n",
            "      üìä 'Cathedra Mass Scheduled for Ju...' -> Score: 10\n",
            "  ‚ùå No parish directory URL found\n",
            "  üíæ Saved result to database\n",
            "  ‚è±Ô∏è Waiting 2 seconds...\n",
            "\\n============================================================\n",
            "Processing diocese 4/5\n",
            "\\nüèõÔ∏è Processing: Diocese of Ogdensburg\n",
            "  üìç URL: https://www.rcdony.org\n",
            "  üì• Loading website...\n",
            "  üîç Scanning for parish directory links...\n",
            "  üìã Found 5 candidate links\n",
            "    ü§ñ Analyzing 5 candidate links...\n",
            "      üìä 'Ministries/Offices...' -> Score: 10\n",
            "      üìä 'Parishes...' -> Score: 50\n",
            "      üìä 'Schools...' -> Score: 10\n",
            "      üìä 'Institutions...' -> Score: 10\n",
            "      üìä 'Parish Bulletins...' -> Score: 50\n",
            "  ‚úÖ Found directory URL: https://www.rcdony.org/directory/parishes.html\n",
            "  üíæ Saved result to database\n",
            "  ‚è±Ô∏è Waiting 2 seconds...\n",
            "\\n============================================================\n",
            "Processing diocese 5/5\n",
            "\\nüèõÔ∏è Processing: Diocese of Camden\n",
            "  üìç URL: https://www.camdendiocese.org\n",
            "  üì• Loading website...\n",
            "  üîç Scanning for parish directory links...\n",
            "  üìã Found 1 candidate links\n",
            "    ü§ñ Analyzing 1 candidate links...\n",
            "      üìä 'Worship & Christian Initiation...' -> Score: 10\n",
            "  ‚ùå No parish directory URL found\n",
            "  üíæ Saved result to database\n",
            "\\nüßπ WebDriver closed\n",
            "\\n============================================================\n",
            "üìä SUMMARY\n",
            "============================================================\n",
            "Total dioceses processed: 5\n",
            "Successfully found directories: 1\n",
            "Failed to find directories: 4\n",
            "Success rate: 20.0%\n",
            "\\nüìã Detailed Results:\n",
            "  ‚ùå Diocese of Des Moines\n",
            "      Method: link_analysis\n",
            "\n",
            "  ‚ùå Armenian Catholic Eparchy of Our Lady of Nareg in the USA & Canada\n",
            "      Method: path_testing\n",
            "\n",
            "  ‚ùå Archdiocese of Kansas City in Kansas\n",
            "      Method: link_analysis\n",
            "\n",
            "  ‚úÖ Diocese of Ogdensburg\n",
            "      Directory: https://www.rcdony.org/directory/parishes.html\n",
            "      Method: link_analysis\n",
            "\n",
            "  ‚ùå Diocese of Camden\n",
            "      Method: link_analysis\n",
            "\n",
            "\\nüéâ Parish directory discovery complete!\n",
            "\\nüìö Next step: Run 03_Extract_Parish_Data.ipynb to extract parish information\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Main Processing Loop - FIXED VERSION\n",
        "\n",
        "def analyze_links_with_fallback(candidate_links, diocese_name=None):\n",
        "    \"\"\"Analyzes candidate links using enhanced keyword scoring.\"\"\"\n",
        "    best_link = None\n",
        "    highest_score = -1\n",
        "\n",
        "    print(f\"    ü§ñ Analyzing {len(candidate_links)} candidate links...\")\n",
        "\n",
        "    for link_info in candidate_links:\n",
        "        try:\n",
        "            # Create analysis context\n",
        "            link_context = f\"Link text: '{link_info['text']}', URL: '{link_info['href']}', Context: '{link_info['surrounding_text'][:100]}'\"\n",
        "\n",
        "            # Use enhanced keyword-based scoring\n",
        "            analysis = fallback_analyze_with_ai(link_context)\n",
        "            score = analysis.get('score', 0)\n",
        "\n",
        "            print(f\"      üìä '{link_info['text'][:30]}...' -> Score: {score}\")\n",
        "\n",
        "            if score >= config.ai_confidence_threshold and score > highest_score:\n",
        "                highest_score = score\n",
        "                best_link = link_info['href']\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      ‚ùå Error analyzing link: {str(e)[:50]}...\")\n",
        "            continue\n",
        "\n",
        "    return best_link\n",
        "\n",
        "def test_directory_paths(diocese_name, diocese_website_url):\n",
        "    \"\"\"Tests common parish directory URL paths to see if they exist.\"\"\"\n",
        "    print(f\"    üîç Testing common directory paths...\")\n",
        "\n",
        "    # Common parish directory paths - expanded with real-world patterns\n",
        "    common_paths = [\n",
        "        '/parishes',\n",
        "        '/directory',\n",
        "        '/parish-directory',\n",
        "        '/find-a-parish',\n",
        "        '/churches',\n",
        "        '/locations',\n",
        "        '/parish-finder',\n",
        "        '/church-directory',\n",
        "        '/find-a-church',\n",
        "        '/parish-listings',\n",
        "        '/parish-map',\n",
        "        '/worship',\n",
        "        '/sacraments',\n",
        "        # Ukrainian Catholic specific patterns\n",
        "        '/en/eparchy/map-of-eparchy.html',\n",
        "        '/eparchy/map-of-eparchy',\n",
        "        '/map-of-eparchy',\n",
        "        '/eparchy/parishes',\n",
        "        '/en/parishes',\n",
        "        # Other common patterns found in real dioceses\n",
        "        '/our-parishes',\n",
        "        '/communities',\n",
        "        '/catholic-churches',\n",
        "        '/church-locator',\n",
        "        '/mass-times',\n",
        "        '/parish-search',\n",
        "        '/ministries',\n",
        "        '/about/parishes'\n",
        "    ]\n",
        "\n",
        "    found_links = []\n",
        "\n",
        "    # Test common directory paths\n",
        "    for path in common_paths:\n",
        "        try:\n",
        "            test_url = normalize_url_join(diocese_website_url, path)\n",
        "            print(f\"      üîç Testing: {test_url}\")\n",
        "\n",
        "            # Use requests to test if URL exists\n",
        "            headers = {\n",
        "                'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36'\n",
        "            }\n",
        "            response = requests.head(test_url, headers=headers, timeout=5, allow_redirects=True)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                # Also check if it's not just redirecting to homepage\n",
        "                if response.url != diocese_website_url and response.url != diocese_website_url + '/':\n",
        "                    found_links.append({\n",
        "                        'link': test_url,\n",
        "                        'title': f\"Parish Directory - {diocese_name}\",\n",
        "                        'snippet': f\"Parish directory found at {path}. Likely contains parish listings and information.\"\n",
        "                    })\n",
        "                    print(f\"      ‚úÖ Found working link: {test_url}\")\n",
        "                else:\n",
        "                    print(f\"      ‚ö†Ô∏è Redirects to homepage: {test_url}\")\n",
        "            else:\n",
        "                print(f\"      ‚ùå {response.status_code}: {test_url}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      ‚ùå Failed: {path} - {str(e)[:30]}...\")\n",
        "            continue\n",
        "\n",
        "    if found_links:\n",
        "        print(f\"    üìã Found {len(found_links)} working directory paths\")\n",
        "        return analyze_directory_candidates(found_links, diocese_name)\n",
        "    else:\n",
        "        print(f\"    ‚ùå No standard directory paths found\")\n",
        "        # Try one more approach - scan the main page more thoroughly\n",
        "        return scan_main_page_deeper(diocese_name, diocese_website_url)\n",
        "\n",
        "def scan_main_page_deeper(diocese_name, diocese_website_url):\n",
        "    \"\"\"Scan the main page more thoroughly for any parish-related links.\"\"\"\n",
        "    print(f\"    üîç Scanning main page more thoroughly...\")\n",
        "\n",
        "    try:\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36'\n",
        "        }\n",
        "        response = requests.get(diocese_website_url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Look for any links that might contain parish information\n",
        "        all_links = soup.find_all('a', href=True)\n",
        "        potential_links = []\n",
        "\n",
        "        for link in all_links:\n",
        "            href = link.get('href', '')\n",
        "            text = link.get_text(strip=True).lower()\n",
        "\n",
        "            # Look for parish-related keywords in link text or href\n",
        "            parish_indicators = [\n",
        "                'parish', 'church', 'community', 'location', 'directory',\n",
        "                '–µ–ø–∞—Ä—Ö—ñ—è', '–ø–∞—Ä–∞—Ñ—ñ—ó', '—Ü–µ—Ä–∫–≤–∏',  # Ukrainian terms\n",
        "                'map', 'find', 'search', 'contact'\n",
        "            ]\n",
        "\n",
        "            if any(indicator in text or indicator in href.lower() for indicator in parish_indicators):\n",
        "                full_url = normalize_url_join(diocese_website_url, href)\n",
        "                if full_url != diocese_website_url:  # Don't include homepage\n",
        "                    potential_links.append({\n",
        "                        'link': full_url,\n",
        "                        'title': f\"Potential Parish Page - {text[:50]}\",\n",
        "                        'snippet': f\"Link text: '{text}' - May contain parish information\"\n",
        "                    })\n",
        "\n",
        "        if potential_links:\n",
        "            print(f\"    üìã Found {len(potential_links)} potential parish-related links\")\n",
        "            # Limit to top 5 most promising\n",
        "            return analyze_directory_candidates(potential_links[:5], diocese_name)\n",
        "        else:\n",
        "            print(f\"    ‚ùå No parish-related links found on main page\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    ‚ùå Error scanning main page: {str(e)[:50]}...\")\n",
        "        return None\n",
        "\n",
        "def analyze_directory_candidates(search_results, diocese_name):\n",
        "    \"\"\"Analyzes potential directory links to find the best one.\"\"\"\n",
        "    best_link = None\n",
        "    highest_score = -1\n",
        "\n",
        "    print(f\"    ü§ñ Analyzing {len(search_results)} potential directory links...\")\n",
        "\n",
        "    for result in search_results:\n",
        "        try:\n",
        "            snippet_context = f\"Title: '{result.get('title', '')}', Snippet: '{result.get('snippet', '')}', URL: '{result.get('link', '')}'\"\n",
        "\n",
        "            # Use enhanced fallback analysis\n",
        "            analysis = fallback_analyze_with_ai(snippet_context)\n",
        "            score = analysis.get('score', 0)\n",
        "\n",
        "            print(f\"      üìä '{result.get('title', '')[:50]}...' -> Score: {score}\")\n",
        "\n",
        "            if score >= config.ai_confidence_threshold and score > highest_score:\n",
        "                highest_score = score\n",
        "                best_link = result.get('link')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      ‚ùå Error analyzing candidate: {str(e)[:50]}...\")\n",
        "            continue\n",
        "\n",
        "    return best_link\n",
        "\n",
        "def process_diocese_for_directory(diocese_info, driver):\n",
        "    \"\"\"Process a single diocese to find its parish directory URL.\"\"\"\n",
        "    diocese_url = diocese_info['url']\n",
        "    diocese_name = diocese_info['name']\n",
        "\n",
        "    print(f\"\\\\nüèõÔ∏è Processing: {diocese_name}\")\n",
        "    print(f\"  üìç URL: {diocese_url}\")\n",
        "\n",
        "    try:\n",
        "        # Load the diocese website\n",
        "        print(f\"  üì• Loading website...\")\n",
        "        soup = fallback_load_page(driver, diocese_url)\n",
        "\n",
        "        if not soup:\n",
        "            raise Exception(\"Failed to load website\")\n",
        "\n",
        "        # Find candidate links\n",
        "        print(f\"  üîç Scanning for parish directory links...\")\n",
        "        candidate_links = find_candidate_urls(soup, diocese_url)\n",
        "\n",
        "        if not candidate_links:\n",
        "            print(f\"  ‚ö†Ô∏è No candidate links found on main page\")\n",
        "            # Try testing common directory paths\n",
        "            directory_url = test_directory_paths(diocese_name, diocese_url)\n",
        "            method = \"path_testing\"\n",
        "        else:\n",
        "            print(f\"  üìã Found {len(candidate_links)} candidate links\")\n",
        "            # Analyze with keyword scoring\n",
        "            directory_url = analyze_links_with_fallback(candidate_links, diocese_name)\n",
        "            method = \"link_analysis\"\n",
        "\n",
        "        # Save result\n",
        "        success = directory_url is not None\n",
        "        if success:\n",
        "            print(f\"  ‚úÖ Found directory URL: {directory_url}\")\n",
        "        else:\n",
        "            print(f\"  ‚ùå No parish directory URL found\")\n",
        "\n",
        "        save_directory_result(diocese_url, directory_url, success, method)\n",
        "\n",
        "        return {\n",
        "            'diocese_name': diocese_name,\n",
        "            'diocese_url': diocese_url,\n",
        "            'directory_url': directory_url,\n",
        "            'success': success,\n",
        "            'method': method\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = str(e)[:100]\n",
        "        print(f\"  ‚ùå Error processing {diocese_name}: {error_msg}\")\n",
        "\n",
        "        # Save error result\n",
        "        save_directory_result(diocese_url, None, False, f\"error: {error_msg}\")\n",
        "\n",
        "        return {\n",
        "            'diocese_name': diocese_name,\n",
        "            'diocese_url': diocese_url,\n",
        "            'directory_url': None,\n",
        "            'success': False,\n",
        "            'method': 'error',\n",
        "            'error': error_msg\n",
        "        }\n",
        "\n",
        "# Set processing limit (you can change this)\n",
        "MAX_DIOCESES_TO_PROCESS = 5  # Process 5 dioceses as a test\n",
        "\n",
        "print(f\"üöÄ Starting parish directory discovery...\")\n",
        "print(f\"üìä Will process up to {MAX_DIOCESES_TO_PROCESS} dioceses\")\n",
        "\n",
        "# Get dioceses to process\n",
        "dioceses_to_scan = get_dioceses_to_process(limit=MAX_DIOCESES_TO_PROCESS)\n",
        "\n",
        "if not dioceses_to_scan:\n",
        "    print(\"‚ùå No dioceses found to process\")\n",
        "    print(\"\\\\nüîß Make sure you've run 01_Build_Dioceses_Database.ipynb first\")\n",
        "else:\n",
        "    print(f\"üìã Found {len(dioceses_to_scan)} dioceses to process\")\n",
        "\n",
        "    # Setup WebDriver using our Colab-specific function\n",
        "    driver = setup_colab_driver()\n",
        "\n",
        "    if not driver:\n",
        "        print(\"‚ùå Failed to setup WebDriver\")\n",
        "    else:\n",
        "        results = []\n",
        "\n",
        "        try:\n",
        "            for i, diocese_info in enumerate(dioceses_to_scan, 1):\n",
        "                print(f\"\\\\n{'='*60}\")\n",
        "                print(f\"Processing diocese {i}/{len(dioceses_to_scan)}\")\n",
        "\n",
        "                result = process_diocese_for_directory(diocese_info, driver)\n",
        "                results.append(result)\n",
        "\n",
        "                # Be respectful - pause between requests\n",
        "                if i < len(dioceses_to_scan):\n",
        "                    print(f\"  ‚è±Ô∏è Waiting {config.request_delay} seconds...\")\n",
        "                    time.sleep(config.request_delay)\n",
        "\n",
        "        finally:\n",
        "            driver.quit()\n",
        "            print(\"\\\\nüßπ WebDriver closed\")\n",
        "\n",
        "        # Print summary\n",
        "        print(f\"\\\\n{'='*60}\")\n",
        "        print(f\"üìä SUMMARY\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        successful = sum(1 for r in results if r['success'])\n",
        "        failed = len(results) - successful\n",
        "\n",
        "        print(f\"Total dioceses processed: {len(results)}\")\n",
        "        print(f\"Successfully found directories: {successful}\")\n",
        "        print(f\"Failed to find directories: {failed}\")\n",
        "        print(f\"Success rate: {successful/len(results)*100:.1f}%\")\n",
        "\n",
        "        print(f\"\\\\nüìã Detailed Results:\")\n",
        "        for result in results:\n",
        "            status = \"‚úÖ\" if result['success'] else \"‚ùå\"\n",
        "            print(f\"  {status} {result['diocese_name']}\")\n",
        "            if result['success']:\n",
        "                print(f\"      Directory: {result['directory_url']}\")\n",
        "            print(f\"      Method: {result['method']}\")\n",
        "            if 'error' in result:\n",
        "                print(f\"      Error: {result['error']}\")\n",
        "            print()\n",
        "\n",
        "        print(\"\\\\nüéâ Parish directory discovery complete!\")\n",
        "        print(\"\\\\nüìö Next step: Run 03_Extract_Parish_Data.ipynb to extract parish information\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}