{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Find Parish Directories\n",
    "\n",
    "This notebook discovers parish directory URLs on diocesan websites using AI-powered analysis.\n",
    "\n",
    "**Prerequisites**: \n",
    "1. Run `00_Colab_Setup.ipynb` first\n",
    "2. Run `01_Build_Dioceses_Database.ipynb` to populate dioceses\n",
    "\n",
    "**What this does**:\n",
    "- Analyzes diocese websites to find parish directory pages\n",
    "- Uses Google Gemini AI for intelligent link classification\n",
    "- Provides fallback search using Google Custom Search API\n",
    "- Saves discovered directory URLs to Supabase database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_environment"
   },
   "outputs": [],
   "source": [
    "# Cell 1: Setup Environment and Imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from datetime import datetime\n",
    "\n",
    "# Ensure we're in the correct directory and set up Python path\n",
    "repo_path = '/content/usccb-parish-extraction'\n",
    "\n",
    "if not os.path.exists(repo_path):\n",
    "    print(\"‚ùå Repository not found!\")\n",
    "    print(\"Please run 00_Colab_Setup.ipynb first to clone the repository.\")\n",
    "    raise FileNotFoundError(\"Repository not found\")\n",
    "\n",
    "# Change to repository directory and add to Python path\n",
    "os.chdir(repo_path)\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.append(repo_path)\n",
    "\n",
    "print(f\"üìÇ Working directory: {os.getcwd()}\")\n",
    "print(\"üêç Python path configured\")\n",
    "\n",
    "# Import required modules\n",
    "try:\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import pandas as pd\n",
    "    import google.generativeai as genai\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    from selenium.webdriver.chrome.service import Service\n",
    "    from webdriver_manager.chrome import ChromeDriverManager\n",
    "    from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "    from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
    "    from google.api_core.exceptions import DeadlineExceeded, ServiceUnavailable, ResourceExhausted\n",
    "    from googleapiclient.discovery import build\n",
    "    from googleapiclient.errors import HttpError\n",
    "    \n",
    "    from config.settings import get_config\n",
    "    from src.utils.webdriver import setup_driver, load_page, clean_text\n",
    "    from src.utils.ai_analysis import analyze_with_ai\n",
    "    \n",
    "    print(\"‚úÖ All modules imported successfully\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"\\nüîß Troubleshooting:\")\n",
    "    print(\"1. Make sure you've run 00_Colab_Setup.ipynb completely\")\n",
    "    print(\"2. If you restarted the runtime, re-run the setup notebook\")\n",
    "    print(\"3. Check that all required packages are installed\")\n",
    "    raise\n",
    "\n",
    "# Get configuration\n",
    "try:\n",
    "    config = get_config()\n",
    "    print(\"‚úÖ Configuration loaded successfully\")\n",
    "    print(f\"üìä Database: {'Connected' if config.supabase else 'Not connected'}\")\n",
    "    print(f\"ü§ñ AI: {'Enabled' if config.genai_enabled else 'Mock mode'}\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"‚ùå Configuration error: {e}\")\n",
    "    print(\"\\nüîß Please run 00_Colab_Setup.ipynb first to configure your environment.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "parish_directory_functions"
   },
   "outputs": [],
   "source": [
    "# Cell 2: Parish Directory Discovery Functions\n",
    "\n",
    "def normalize_url_join(base_url, relative_url):\n",
    "    \"\"\"Properly joins URLs while avoiding double slashes.\"\"\"\n",
    "    if base_url.endswith('/') and relative_url.startswith('/'):\n",
    "        base_url = base_url.rstrip('/')\n",
    "    return urljoin(base_url, relative_url)\n",
    "\n",
    "def get_surrounding_text(element, max_length=200):\n",
    "    \"\"\"Extracts context text from the parent element of a link.\"\"\"\n",
    "    if element and element.parent:\n",
    "        parent_text = element.parent.get_text(separator=' ', strip=True)\n",
    "        return parent_text[:max_length] + ('...' if len(parent_text) > max_length else '')\n",
    "    return ''\n",
    "\n",
    "def find_candidate_urls(soup, base_url):\n",
    "    \"\"\"Scans a webpage for potential parish directory links.\"\"\"\n",
    "    candidate_links = []\n",
    "    processed_hrefs = set()\n",
    "\n",
    "    # Keywords likely to appear in parish directory links\n",
    "    parish_link_keywords = [\n",
    "        'Churches', 'Directory of Parishes', 'Parishes', 'parishfinder', 'Parish Finder',\n",
    "        'Find a Parish', 'Locations', 'Our Parishes', 'Parish Listings', 'Find a Church',\n",
    "        'Church Directory', 'Faith Communities', 'Find Mass Times', 'Our Churches',\n",
    "        'Search Parishes', 'Parish Map', 'Mass Schedule', 'Sacraments', 'Worship'\n",
    "    ]\n",
    "    \n",
    "    # URL path patterns for parish directories\n",
    "    url_patterns = [\n",
    "        r'parishes', r'directory', r'locations', r'churches',\n",
    "        r'parish-finder', r'findachurch', r'parishsearch', r'parishdirectory',\n",
    "        r'find-a-church', r'church-directory', r'parish-listings', r'parish-map',\n",
    "        r'mass-times', r'sacraments', r'search', r'worship', r'finder'\n",
    "    ]\n",
    "\n",
    "    all_links = soup.find_all('a', href=True)\n",
    "\n",
    "    for link_tag in all_links:\n",
    "        href = link_tag['href']\n",
    "        if not href or href.startswith('#') or href.lower().startswith('javascript:') or href.lower().startswith('mailto:'):\n",
    "            continue\n",
    "\n",
    "        abs_href = normalize_url_join(base_url, href)\n",
    "        if not abs_href.startswith('http') or abs_href in processed_hrefs:\n",
    "            continue\n",
    "\n",
    "        link_text = link_tag.get_text(strip=True)\n",
    "        surrounding_text = get_surrounding_text(link_tag)\n",
    "        parsed_href_path = urlparse(abs_href).path.lower()\n",
    "\n",
    "        # Check for matches based on keywords or URL patterns\n",
    "        text_match = any(keyword.lower() in link_text.lower() or keyword.lower() in surrounding_text.lower() \n",
    "                        for keyword in parish_link_keywords)\n",
    "        pattern_match = any(re.search(pattern, parsed_href_path, re.IGNORECASE) \n",
    "                           for pattern in url_patterns)\n",
    "\n",
    "        if text_match or pattern_match:\n",
    "            candidate_links.append({\n",
    "                'text': link_text,\n",
    "                'href': abs_href,\n",
    "                'surrounding_text': surrounding_text\n",
    "            })\n",
    "            processed_hrefs.add(abs_href)\n",
    "\n",
    "    return candidate_links\n",
    "\n",
    "def analyze_links_with_ai(candidate_links, diocese_name=None):\n",
    "    \"\"\"Analyzes candidate links using AI to find the best parish directory URL.\"\"\"\n",
    "    best_link = None\n",
    "    highest_score = -1\n",
    "\n",
    "    print(f\"    ü§ñ Analyzing {len(candidate_links)} candidate links with AI...\")\n",
    "\n",
    "    for link_info in candidate_links:\n",
    "        try:\n",
    "            # Create analysis prompt\n",
    "            link_context = f\"Link text: '{link_info['text']}', URL: '{link_info['href']}', Context: '{link_info['surrounding_text'][:100]}'\"\n",
    "            \n",
    "            # Use the AI analysis utility\n",
    "            analysis = analyze_with_ai(link_context, \"parish_directory\")\n",
    "            score = analysis.get('score', 0)\n",
    "\n",
    "            print(f\"      üìä '{link_info['text'][:30]}...' -> Score: {score}\")\n",
    "\n",
    "            if score >= config.ai_confidence_threshold and score > highest_score:\n",
    "                highest_score = score\n",
    "                best_link = link_info['href']\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"      ‚ùå Error analyzing link: {str(e)[:50]}...\")\n",
    "            continue\n",
    "\n",
    "    return best_link\n",
    "\n",
    "print(\"‚úÖ Parish directory discovery functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "search_fallback_functions"
   },
   "outputs": [],
   "source": [
    "# Cell 3: Search Engine Fallback Functions\n",
    "\n",
    "def search_for_directory_link(diocese_name, diocese_website_url):\n",
    "    \"\"\"Uses Google Custom Search as fallback to find parish directory links.\"\"\"\n",
    "    print(f\"    üîç Using search engine fallback for {diocese_name}...\")\n",
    "    \n",
    "    # Mock search results if no API keys configured\n",
    "    if not config.genai_enabled:\n",
    "        print(f\"    üìù Using mock search results\")\n",
    "        mock_results = [\n",
    "            {\n",
    "                'link': normalize_url_join(diocese_website_url, '/parishes'),\n",
    "                'title': f\"Parishes - {diocese_name}\",\n",
    "                'snippet': f\"List of parishes in the Diocese of {diocese_name}. Find a parish near you.\"\n",
    "            },\n",
    "            {\n",
    "                'link': normalize_url_join(diocese_website_url, '/directory'),\n",
    "                'title': f\"Directory - {diocese_name}\",\n",
    "                'snippet': f\"Official directory of churches and schools for {diocese_name}.\"\n",
    "            },\n",
    "            {\n",
    "                'link': normalize_url_join(diocese_website_url, '/find-a-church'),\n",
    "                'title': f\"Find a Church - {diocese_name}\",\n",
    "                'snippet': f\"Search for a Catholic church in {diocese_name}. Mass times and locations.\"\n",
    "            }\n",
    "        ]\n",
    "        return analyze_search_snippets_with_ai(mock_results, diocese_name)\n",
    "    \n",
    "    # If we reach here, we would implement actual Google Custom Search\n",
    "    # For now, return None to indicate search not available\n",
    "    print(f\"    ‚ö†Ô∏è Live search not implemented in this simplified version\")\n",
    "    return None\n",
    "\n",
    "def analyze_search_snippets_with_ai(search_results, diocese_name):\n",
    "    \"\"\"Analyzes search result snippets to find the best parish directory URL.\"\"\"\n",
    "    best_link = None\n",
    "    highest_score = -1\n",
    "\n",
    "    print(f\"    ü§ñ Analyzing {len(search_results)} search snippets with AI...\")\n",
    "\n",
    "    for result in search_results:\n",
    "        try:\n",
    "            snippet_context = f\"Title: '{result.get('title', '')}', Snippet: '{result.get('snippet', '')}', URL: '{result.get('link', '')}'\"\n",
    "            \n",
    "            analysis = analyze_with_ai(snippet_context, \"parish_directory\")\n",
    "            score = analysis.get('score', 0)\n",
    "\n",
    "            print(f\"      üìä '{result.get('title', '')[:30]}...' -> Score: {score}\")\n",
    "\n",
    "            if score >= config.ai_confidence_threshold and score > highest_score:\n",
    "                highest_score = score\n",
    "                best_link = result.get('link')\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"      ‚ùå Error analyzing snippet: {str(e)[:50]}...\")\n",
    "            continue\n",
    "\n",
    "    return best_link\n",
    "\n",
    "print(\"‚úÖ Search fallback functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "database_functions"
   },
   "outputs": [],
   "source": [
    "# Cell 4: Database Functions\n",
    "\n",
    "def get_dioceses_to_process(limit=None):\n",
    "    \"\"\"Get dioceses that need parish directory URL discovery.\"\"\"\n",
    "    if not config.supabase:\n",
    "        print(\"‚ùå No database connection\")\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Get all dioceses\n",
    "        response = config.supabase.table('Dioceses').select('Website, Name').execute()\n",
    "        all_dioceses = response.data or []\n",
    "        \n",
    "        # Get dioceses that already have directory URLs\n",
    "        processed_response = config.supabase.table('DiocesesParishDirectory').select(\n",
    "            'diocese_url'\n",
    "        ).not_.is_('parish_directory_url', 'null').not_.eq('parish_directory_url', '').execute()\n",
    "        \n",
    "        processed_urls = {item['diocese_url'] for item in (processed_response.data or [])}\n",
    "        \n",
    "        # Filter to unprocessed dioceses\n",
    "        unprocessed = [\n",
    "            {'url': d['Website'], 'name': d['Name']}\n",
    "            for d in all_dioceses\n",
    "            if d['Website'] not in processed_urls\n",
    "        ]\n",
    "        \n",
    "        if limit and len(unprocessed) > limit:\n",
    "            import random\n",
    "            unprocessed = random.sample(unprocessed, limit)\n",
    "        \n",
    "        return unprocessed\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error fetching dioceses: {e}\")\n",
    "        return []\n",
    "\n",
    "def save_directory_result(diocese_url, directory_url, success, method=\"ai_analysis\"):\n",
    "    \"\"\"Save parish directory discovery result to database.\"\"\"\n",
    "    if not config.supabase:\n",
    "        print(f\"  üìù Would save: {diocese_url} -> {directory_url or 'Not Found'}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        data = {\n",
    "            'diocese_url': diocese_url,\n",
    "            'parish_directory_url': directory_url,\n",
    "            'found': 'Success' if success else 'Not Found',\n",
    "            'found_method': method,\n",
    "            'updated_at': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        config.supabase.table('DiocesesParishDirectory').upsert(data).execute()\n",
    "        print(f\"  üíæ Saved result to database\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error saving to database: {e}\")\n",
    "\n",
    "print(\"‚úÖ Database functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "main_processing"
   },
   "outputs": [],
   "source": [
    "# Cell 5: Main Processing Loop\n",
    "\n",
    "def process_diocese_for_directory(diocese_info, driver):\n",
    "    \"\"\"Process a single diocese to find its parish directory URL.\"\"\"\n",
    "    diocese_url = diocese_info['url']\n",
    "    diocese_name = diocese_info['name']\n",
    "    \n",
    "    print(f\"\\nüèõÔ∏è Processing: {diocese_name}\")\n",
    "    print(f\"  üìç URL: {diocese_url}\")\n",
    "    \n",
    "    try:\n",
    "        # Load the diocese website\n",
    "        print(f\"  üì• Loading website...\")\n",
    "        soup = load_page(driver, diocese_url)\n",
    "        \n",
    "        # Find candidate links\n",
    "        print(f\"  üîç Scanning for parish directory links...\")\n",
    "        candidate_links = find_candidate_urls(soup, diocese_url)\n",
    "        \n",
    "        if not candidate_links:\n",
    "            print(f\"  ‚ö†Ô∏è No candidate links found on main page\")\n",
    "            # Try search engine fallback\n",
    "            directory_url = search_for_directory_link(diocese_name, diocese_url)\n",
    "            method = \"search_engine_fallback\"\n",
    "        else:\n",
    "            print(f\"  üìã Found {len(candidate_links)} candidate links\")\n",
    "            # Analyze with AI\n",
    "            directory_url = analyze_links_with_ai(candidate_links, diocese_name)\n",
    "            method = \"ai_direct_analysis\"\n",
    "        \n",
    "        # Save result\n",
    "        success = directory_url is not None\n",
    "        if success:\n",
    "            print(f\"  ‚úÖ Found directory URL: {directory_url}\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå No parish directory URL found\")\n",
    "        \n",
    "        save_directory_result(diocese_url, directory_url, success, method)\n",
    "        \n",
    "        return {\n",
    "            'diocese_name': diocese_name,\n",
    "            'diocese_url': diocese_url,\n",
    "            'directory_url': directory_url,\n",
    "            'success': success,\n",
    "            'method': method\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)[:100]\n",
    "        print(f\"  ‚ùå Error processing {diocese_name}: {error_msg}\")\n",
    "        \n",
    "        # Save error result\n",
    "        save_directory_result(diocese_url, None, False, f\"error: {error_msg}\")\n",
    "        \n",
    "        return {\n",
    "            'diocese_name': diocese_name,\n",
    "            'diocese_url': diocese_url,\n",
    "            'directory_url': None,\n",
    "            'success': False,\n",
    "            'method': 'error',\n",
    "            'error': error_msg\n",
    "        }\n",
    "\n",
    "# Set processing limit (you can change this)\n",
    "MAX_DIOCESES_TO_PROCESS = 5  # Process 5 dioceses as a test\n",
    "\n",
    "print(f\"üöÄ Starting parish directory discovery...\")\n",
    "print(f\"üìä Will process up to {MAX_DIOCESES_TO_PROCESS} dioceses\")\n",
    "\n",
    "# Get dioceses to process\n",
    "dioceses_to_scan = get_dioceses_to_process(limit=MAX_DIOCESES_TO_PROCESS)\n",
    "\n",
    "if not dioceses_to_scan:\n",
    "    print(\"‚ùå No dioceses found to process\")\n",
    "else:\n",
    "    print(f\"üìã Found {len(dioceses_to_scan)} dioceses to process\")\n",
    "    \n",
    "    # Setup WebDriver\n",
    "    driver = setup_driver()\n",
    "    \n",
    "    if not driver:\n",
    "        print(\"‚ùå Failed to setup WebDriver\")\n",
    "    else:\n",
    "        results = []\n",
    "        \n",
    "        try:\n",
    "            for i, diocese_info in enumerate(dioceses_to_scan, 1):\n",
    "                print(f\"\\n{'='*60}\")\n",
    "                print(f\"Processing diocese {i}/{len(dioceses_to_scan)}\")\n",
    "                \n",
    "                result = process_diocese_for_directory(diocese_info, driver)\n",
    "                results.append(result)\n",
    "                \n",
    "                # Be respectful - pause between requests\n",
    "                if i < len(dioceses_to_scan):\n",
    "                    print(f\"  ‚è±Ô∏è Waiting {config.request_delay} seconds...\")\n",
    "                    time.sleep(config.request_delay)\n",
    "        \n",
    "        finally:\n",
    "            driver.quit()\n",
    "            print(\"\\nüßπ WebDriver closed\")\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üìä SUMMARY\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        successful = sum(1 for r in results if r['success'])\n",
    "        failed = len(results) - successful\n",
    "        \n",
    "        print(f\"Total dioceses processed: {len(results)}\")\n",
    "        print(f\"Successfully found directories: {successful}\")\n",
    "        print(f\"Failed to find directories: {failed}\")\n",
    "        print(f\"Success rate: {successful/len(results)*100:.1f}%\")\n",
    "        \n",
    "        print(f\"\\nüìã Detailed Results:\")\n",
    "        for result in results:\n",
    "            status = \"‚úÖ\" if result['success'] else \"‚ùå\"\n",
    "            print(f\"  {status} {result['diocese_name']}\")\n",
    "            if result['success']:\n",
    "                print(f\"      Directory: {result['directory_url']}\")\n",
    "            print(f\"      Method: {result['method']}\")\n",
    "            if 'error' in result:\n",
    "                print(f\"      Error: {result['error']}\")\n",
    "            print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
